{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "513e71e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 78.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akagg\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\akagg\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 49152)             4915200   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 128, 128, 128)     6144      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 128)       262144    \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 64, 64, 128)       512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 256)       524288    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 256)       1048576   \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 32, 32, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTr  (None, 32, 32, 512)       2097152   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 512)       4194304   \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2D  (None, 16, 16, 512)       4194304   \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2D  (None, 32, 32, 512)       4194304   \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 32, 32, 512)       2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 32, 32, 512)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2D  (None, 32, 32, 256)       2097152   \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2D  (None, 64, 64, 256)       1048576   \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 64, 64, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2D  (None, 128, 128, 128)     524288    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2D  (None, 128, 128, 128)     262144    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 128, 128, 128)     512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_7 (Conv2D  (None, 128, 128, 3)       6147      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25379843 (96.82 MB)\n",
      "Trainable params: 25377283 (96.81 MB)\n",
      "Non-trainable params: 2560 (10.00 KB)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 64, 64, 128)       6144      \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 64, 64, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 32, 32, 128)       262144    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 32, 32, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 16, 16, 256)       524288    \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 16, 16, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 8, 8, 256)         1048576   \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 8, 8, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 512)         2097152   \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 8193      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3949569 (15.07 MB)\n",
      "Trainable params: 3948033 (15.06 MB)\n",
      "Non-trainable params: 1536 (6.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akagg\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\legacy\\rmsprop.py:144: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akagg\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:5818: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Time:17.0\n",
      "Generator Loss: 0.5251317024230957 Discriminator Loss: 1.4136260747909546\n",
      "\n",
      "Epoch : 2\n",
      " Time:15.0\n",
      "Generator Loss: 0.016531992703676224 Discriminator Loss: 4.168893337249756\n",
      "\n",
      "Epoch : 3\n",
      " Time:14.0\n",
      "Generator Loss: 17.401226043701172 Discriminator Loss: 0.10913374274969101\n",
      "\n",
      "Epoch : 4\n",
      " Time:15.0\n",
      "Generator Loss: 0.0024587130174040794 Discriminator Loss: 6.093887805938721\n",
      "\n",
      "Epoch : 5\n",
      " Time:14.0\n",
      "Generator Loss: 17.969562530517578 Discriminator Loss: 0.39032265543937683\n",
      "\n",
      "Epoch : 6\n",
      " Time:14.0\n",
      "Generator Loss: 7.24554967880249 Discriminator Loss: 0.005954669788479805\n",
      "\n",
      "Epoch : 7\n",
      " Time:14.0\n",
      "Generator Loss: 8.324498776346445e-05 Discriminator Loss: 9.41015911102295\n",
      "\n",
      "Epoch : 8\n",
      " Time:14.0\n",
      "Generator Loss: 11.684460639953613 Discriminator Loss: 0.16130389273166656\n",
      "\n",
      "Epoch : 9\n",
      " Time:14.0\n",
      "Generator Loss: 3.046706199645996 Discriminator Loss: 0.08826618641614914\n",
      "\n",
      "Epoch : 10\n",
      " Time:15.0\n",
      "Generator Loss: 1.9750621318817139 Discriminator Loss: 0.18599915504455566\n",
      "\n",
      "Epoch : 11\n",
      " Time:14.0\n",
      "Generator Loss: 4.953974723815918 Discriminator Loss: 0.0672786757349968\n",
      "\n",
      "Epoch : 12\n",
      " Time:14.0\n",
      "Generator Loss: 2.944257974624634 Discriminator Loss: 0.08600539714097977\n",
      "\n",
      "Epoch : 13\n",
      " Time:14.0\n",
      "Generator Loss: 3.3363497257232666 Discriminator Loss: 0.06676197052001953\n",
      "\n",
      "Epoch : 14\n",
      " Time:14.0\n",
      "Generator Loss: 3.5054311752319336 Discriminator Loss: 0.05839136242866516\n",
      "\n",
      "Epoch : 15\n",
      " Time:14.0\n",
      "Generator Loss: 3.7236671447753906 Discriminator Loss: 0.05088195949792862\n",
      "\n",
      "Epoch : 16\n",
      " Time:14.0\n",
      "Generator Loss: 4.386699676513672 Discriminator Loss: 0.03633365035057068\n",
      "\n",
      "Epoch : 17\n",
      " Time:14.0\n",
      "Generator Loss: 4.729982376098633 Discriminator Loss: 0.028033563867211342\n",
      "\n",
      "Epoch : 18\n",
      " Time:14.0\n",
      "Generator Loss: 3.804830551147461 Discriminator Loss: 0.038380932062864304\n",
      "\n",
      "Epoch : 19\n",
      " Time:14.0\n",
      "Generator Loss: 2.930933952331543 Discriminator Loss: 0.07798309624195099\n",
      "\n",
      "Epoch : 20\n",
      " Time:14.0\n",
      "Generator Loss: 10.438112258911133 Discriminator Loss: 0.031165290623903275\n",
      "\n",
      "Epoch : 21\n",
      " Time:14.0\n",
      "Generator Loss: 3.455690383911133 Discriminator Loss: 0.048240065574645996\n",
      "\n",
      "Epoch : 22\n",
      " Time:14.0\n",
      "Generator Loss: 3.1787800788879395 Discriminator Loss: 0.06517581641674042\n",
      "\n",
      "Epoch : 23\n",
      " Time:14.0\n",
      "Generator Loss: 6.234733581542969 Discriminator Loss: 0.034182336181402206\n",
      "\n",
      "Epoch : 24\n",
      " Time:15.0\n",
      "Generator Loss: 0.8166514039039612 Discriminator Loss: 0.6135409474372864\n",
      "\n",
      "Epoch : 25\n",
      " Time:14.0\n",
      "Generator Loss: 21.88814926147461 Discriminator Loss: 0.5347558856010437\n",
      "\n",
      "Epoch : 26\n",
      " Time:14.0\n",
      "Generator Loss: 1.5475890636444092 Discriminator Loss: 0.2671751379966736\n",
      "\n",
      "Epoch : 27\n",
      " Time:14.0\n",
      "Generator Loss: 6.743014335632324 Discriminator Loss: 0.004039354622364044\n",
      "\n",
      "Epoch : 28\n",
      " Time:15.0\n",
      "Generator Loss: 0.9175552129745483 Discriminator Loss: 0.6051572561264038\n",
      "\n",
      "Epoch : 29\n",
      " Time:14.0\n",
      "Generator Loss: 7.986957550048828 Discriminator Loss: 0.11726094037294388\n",
      "\n",
      "Epoch : 30\n",
      " Time:15.0\n",
      "Generator Loss: 5.234213829040527 Discriminator Loss: 0.01747162453830242\n",
      "\n",
      "Epoch : 31\n",
      " Time:15.0\n",
      "Generator Loss: 1.5098416805267334 Discriminator Loss: 0.2865009605884552\n",
      "\n",
      "Epoch : 32\n",
      " Time:16.0\n",
      "Generator Loss: 3.86232328414917 Discriminator Loss: 0.05563630163669586\n",
      "\n",
      "Epoch : 33\n",
      " Time:15.0\n",
      "Generator Loss: 8.170186996459961 Discriminator Loss: 0.01825891062617302\n",
      "\n",
      "Epoch : 34\n",
      " Time:15.0\n",
      "Generator Loss: 3.4912028312683105 Discriminator Loss: 0.04604100063443184\n",
      "\n",
      "Epoch : 35\n",
      " Time:15.0\n",
      "Generator Loss: 1.6816613674163818 Discriminator Loss: 0.25200027227401733\n",
      "\n",
      "Epoch : 36\n",
      " Time:14.0\n",
      "Generator Loss: 2.227074384689331 Discriminator Loss: 0.1826315075159073\n",
      "\n",
      "Epoch : 37\n",
      " Time:14.0\n",
      "Generator Loss: 1.9786057472229004 Discriminator Loss: 0.2825586497783661\n",
      "\n",
      "Epoch : 38\n",
      " Time:15.0\n",
      "Generator Loss: 4.528921604156494 Discriminator Loss: 0.2089121788740158\n",
      "\n",
      "Epoch : 39\n",
      " Time:15.0\n",
      "Generator Loss: 1.0626028776168823 Discriminator Loss: 0.6101686954498291\n",
      "\n",
      "Epoch : 40\n",
      " Time:15.0\n",
      "Generator Loss: 2.021904706954956 Discriminator Loss: 0.2612398862838745\n",
      "\n",
      "Epoch : 41\n",
      " Time:15.0\n",
      "Generator Loss: 2.056260585784912 Discriminator Loss: 0.275265634059906\n",
      "\n",
      "Epoch : 42\n",
      " Time:15.0\n",
      "Generator Loss: 2.012894868850708 Discriminator Loss: 0.2164435237646103\n",
      "\n",
      "Epoch : 43\n",
      " Time:15.0\n",
      "Generator Loss: 4.198229789733887 Discriminator Loss: 0.08407776057720184\n",
      "\n",
      "Epoch : 44\n",
      " Time:14.0\n",
      "Generator Loss: 1.825776219367981 Discriminator Loss: 0.24991558492183685\n",
      "\n",
      "Epoch : 45\n",
      " Time:14.0\n",
      "Generator Loss: 1.7746944427490234 Discriminator Loss: 0.40797507762908936\n",
      "\n",
      "Epoch : 46\n",
      " Time:15.0\n",
      "Generator Loss: 0.6812998652458191 Discriminator Loss: 1.3213025331497192\n",
      "\n",
      "Epoch : 47\n",
      " Time:15.0\n",
      "Generator Loss: 4.09219217300415 Discriminator Loss: 2.9619083404541016\n",
      "\n",
      "Epoch : 48\n",
      " Time:14.0\n",
      "Generator Loss: 0.028720390051603317 Discriminator Loss: 4.579141139984131\n",
      "\n",
      "Epoch : 49\n",
      " Time:14.0\n",
      "Generator Loss: 4.303907871246338 Discriminator Loss: 0.0219219159334898\n",
      "\n",
      "Epoch : 50\n",
      " Time:14.0\n",
      "Generator Loss: 0.3141584098339081 Discriminator Loss: 1.501286506652832\n",
      "\n",
      "Epoch : 51\n",
      " Time:14.0\n",
      "Generator Loss: 0.46672481298446655 Discriminator Loss: 1.1726620197296143\n",
      "\n",
      "Epoch : 52\n",
      " Time:14.0\n",
      "Generator Loss: 0.8464643955230713 Discriminator Loss: 0.7247781157493591\n",
      "\n",
      "Epoch : 53\n",
      " Time:14.0\n",
      "Generator Loss: 1.1129722595214844 Discriminator Loss: 0.5728358030319214\n",
      "\n",
      "Epoch : 54\n",
      " Time:15.0\n",
      "Generator Loss: 0.8805569410324097 Discriminator Loss: 0.7548388242721558\n",
      "\n",
      "Epoch : 55\n",
      " Time:15.0\n",
      "Generator Loss: 1.166048288345337 Discriminator Loss: 0.5631217956542969\n",
      "\n",
      "Epoch : 56\n",
      " Time:15.0\n",
      "Generator Loss: 1.1247925758361816 Discriminator Loss: 0.6534803509712219\n",
      "\n",
      "Epoch : 57\n",
      " Time:14.0\n",
      "Generator Loss: 1.3026578426361084 Discriminator Loss: 0.6984217166900635\n",
      "\n",
      "Epoch : 58\n",
      " Time:15.0\n",
      "Generator Loss: 0.8143046498298645 Discriminator Loss: 0.8306463360786438\n",
      "\n",
      "Epoch : 59\n",
      " Time:14.0\n",
      "Generator Loss: 1.7493255138397217 Discriminator Loss: 2.055356740951538\n",
      "\n",
      "Epoch : 60\n",
      " Time:14.0\n",
      "Generator Loss: 0.06818221509456635 Discriminator Loss: 3.873964786529541\n",
      "\n",
      "Epoch : 61\n",
      " Time:14.0\n",
      "Generator Loss: 1.2348487377166748 Discriminator Loss: 0.43900051712989807\n",
      "\n",
      "Epoch : 62\n",
      " Time:14.0\n",
      "Generator Loss: 8.291362762451172 Discriminator Loss: 0.1628962755203247\n",
      "\n",
      "Epoch : 63\n",
      " Time:14.0\n",
      "Generator Loss: 1.6484134197235107 Discriminator Loss: 0.2878156304359436\n",
      "\n",
      "Epoch : 64\n",
      " Time:14.0\n",
      "Generator Loss: 4.842153549194336 Discriminator Loss: 0.06343938410282135\n",
      "\n",
      "Epoch : 65\n",
      " Time:15.0\n",
      "Generator Loss: 5.38206148147583 Discriminator Loss: 0.023197008296847343\n",
      "\n",
      "Epoch : 66\n",
      " Time:14.0\n",
      "Generator Loss: 3.6091325283050537 Discriminator Loss: 0.0452134907245636\n",
      "\n",
      "Epoch : 67\n",
      " Time:14.0\n",
      "Generator Loss: 2.012601137161255 Discriminator Loss: 0.18191681802272797\n",
      "\n",
      "Epoch : 68\n",
      " Time:15.0\n",
      "Generator Loss: 1.8126753568649292 Discriminator Loss: 0.2701016962528229\n",
      "\n",
      "Epoch : 69\n",
      " Time:14.0\n",
      "Generator Loss: 1.5636577606201172 Discriminator Loss: 0.34975162148475647\n",
      "\n",
      "Epoch : 70\n",
      " Time:15.0\n",
      "Generator Loss: 1.527987003326416 Discriminator Loss: 0.4883134365081787\n",
      "\n",
      "Epoch : 71\n",
      " Time:15.0\n",
      "Generator Loss: 0.8562299013137817 Discriminator Loss: 0.6901519298553467\n",
      "\n",
      "Epoch : 72\n",
      " Time:14.0\n",
      "Generator Loss: 2.1866455078125 Discriminator Loss: 1.1788862943649292\n",
      "\n",
      "Epoch : 73\n",
      " Time:15.0\n",
      "Generator Loss: 0.26303642988204956 Discriminator Loss: 2.2245020866394043\n",
      "\n",
      "Epoch : 74\n",
      " Time:14.0\n",
      "Generator Loss: 0.22392798960208893 Discriminator Loss: 1.916189432144165\n",
      "\n",
      "Epoch : 75\n",
      " Time:15.0\n",
      "Generator Loss: 0.9741418957710266 Discriminator Loss: 1.0163508653640747\n",
      "\n",
      "Epoch : 76\n",
      " Time:14.0\n",
      "Generator Loss: 1.4002504348754883 Discriminator Loss: 0.36911362409591675\n",
      "\n",
      "Epoch : 77\n",
      " Time:15.0\n",
      "Generator Loss: 2.045989990234375 Discriminator Loss: 0.4669962525367737\n",
      "\n",
      "Epoch : 78\n",
      " Time:15.0\n",
      "Generator Loss: 0.9010375738143921 Discriminator Loss: 0.603502094745636\n",
      "\n",
      "Epoch : 79\n",
      " Time:15.0\n",
      "Generator Loss: 1.7386643886566162 Discriminator Loss: 0.3589133024215698\n",
      "\n",
      "Epoch : 80\n",
      " Time:14.0\n",
      "Generator Loss: 1.9385451078414917 Discriminator Loss: 0.2479781210422516\n",
      "\n",
      "Epoch : 81\n",
      " Time:14.0\n",
      "Generator Loss: 2.168671131134033 Discriminator Loss: 0.21280281245708466\n",
      "\n",
      "Epoch : 82\n",
      " Time:14.0\n",
      "Generator Loss: 1.771273136138916 Discriminator Loss: 0.29498350620269775\n",
      "\n",
      "Epoch : 83\n",
      " Time:14.0\n",
      "Generator Loss: 1.8429728746414185 Discriminator Loss: 0.5257730484008789\n",
      "\n",
      "Epoch : 84\n",
      " Time:14.0\n",
      "Generator Loss: 0.9119506478309631 Discriminator Loss: 0.744451642036438\n",
      "\n",
      "Epoch : 85\n",
      " Time:14.0\n",
      "Generator Loss: 1.4976027011871338 Discriminator Loss: 1.6160012483596802\n",
      "\n",
      "Epoch : 86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Time:14.0\n",
      "Generator Loss: 0.1787528693675995 Discriminator Loss: 2.1839826107025146\n",
      "\n",
      "Epoch : 87\n",
      " Time:14.0\n",
      "Generator Loss: 2.066757917404175 Discriminator Loss: 0.6344411969184875\n",
      "\n",
      "Epoch : 88\n",
      " Time:15.0\n",
      "Generator Loss: 1.2265549898147583 Discriminator Loss: 0.4341661334037781\n",
      "\n",
      "Epoch : 89\n",
      " Time:15.0\n",
      "Generator Loss: 2.0895984172821045 Discriminator Loss: 0.22361689805984497\n",
      "\n",
      "Epoch : 90\n",
      " Time:15.0\n",
      "Generator Loss: 4.445986747741699 Discriminator Loss: 0.021952398121356964\n",
      "\n",
      "Epoch : 91\n",
      " Time:15.0\n",
      "Generator Loss: 1.456120491027832 Discriminator Loss: 0.31677955389022827\n",
      "\n",
      "Epoch : 92\n",
      " Time:15.0\n",
      "Generator Loss: 1.8193998336791992 Discriminator Loss: 0.2896632254123688\n",
      "\n",
      "Epoch : 93\n",
      " Time:16.0\n",
      "Generator Loss: 1.2163678407669067 Discriminator Loss: 0.41082602739334106\n",
      "\n",
      "Epoch : 94\n",
      " Time:15.0\n",
      "Generator Loss: 2.517625093460083 Discriminator Loss: 0.583315372467041\n",
      "\n",
      "Epoch : 95\n",
      " Time:15.0\n",
      "Generator Loss: 0.8507996797561646 Discriminator Loss: 0.7058178782463074\n",
      "\n",
      "Epoch : 96\n",
      " Time:15.0\n",
      "Generator Loss: 0.3357269763946533 Discriminator Loss: 1.446703314781189\n",
      "\n",
      "Epoch : 97\n",
      " Time:15.0\n",
      "Generator Loss: 3.9464914798736572 Discriminator Loss: 0.2700698673725128\n",
      "\n",
      "Epoch : 98\n",
      " Time:15.0\n",
      "Generator Loss: 2.447258710861206 Discriminator Loss: 0.11890102177858353\n",
      "\n",
      "Epoch : 99\n",
      " Time:16.0\n",
      "Generator Loss: 1.4363800287246704 Discriminator Loss: 0.31382519006729126\n",
      "\n",
      "Epoch : 100\n",
      " Time:16.0\n",
      "Generator Loss: 2.1744141578674316 Discriminator Loss: 0.15654340386390686\n",
      "\n",
      "Epoch : 101\n",
      " Time:16.0\n",
      "Generator Loss: 2.4289865493774414 Discriminator Loss: 0.1663370132446289\n",
      "\n",
      "Epoch : 102\n",
      " Time:16.0\n",
      "Generator Loss: 2.329677104949951 Discriminator Loss: 0.15500009059906006\n",
      "\n",
      "Epoch : 103\n",
      " Time:16.0\n",
      "Generator Loss: 3.589456081390381 Discriminator Loss: 0.10011501610279083\n",
      "\n",
      "Epoch : 104\n",
      " Time:16.0\n",
      "Generator Loss: 1.3843283653259277 Discriminator Loss: 0.3451865017414093\n",
      "\n",
      "Epoch : 105\n",
      " Time:16.0\n",
      "Generator Loss: 3.3472468852996826 Discriminator Loss: 2.0002825260162354\n",
      "\n",
      "Epoch : 106\n",
      " Time:16.0\n",
      "Generator Loss: 0.00428445590659976 Discriminator Loss: 5.906510353088379\n",
      "\n",
      "Epoch : 107\n",
      " Time:16.0\n",
      "Generator Loss: 1.2531623840332031 Discriminator Loss: 0.3912181556224823\n",
      "\n",
      "Epoch : 108\n",
      " Time:15.0\n",
      "Generator Loss: 0.1648164540529251 Discriminator Loss: 2.2407631874084473\n",
      "\n",
      "Epoch : 109\n",
      " Time:16.0\n",
      "Generator Loss: 2.7349588871002197 Discriminator Loss: 0.20374612510204315\n",
      "\n",
      "Epoch : 110\n",
      " Time:16.0\n",
      "Generator Loss: 1.7429347038269043 Discriminator Loss: 0.230694979429245\n",
      "\n",
      "Epoch : 111\n",
      " Time:16.0\n",
      "Generator Loss: 1.1057000160217285 Discriminator Loss: 0.46466416120529175\n",
      "\n",
      "Epoch : 112\n",
      " Time:16.0\n",
      "Generator Loss: 0.718891978263855 Discriminator Loss: 0.8198180198669434\n",
      "\n",
      "Epoch : 113\n",
      " Time:16.0\n",
      "Generator Loss: 3.318958282470703 Discriminator Loss: 0.5091806650161743\n",
      "\n",
      "Epoch : 114\n",
      " Time:16.0\n",
      "Generator Loss: 2.489992141723633 Discriminator Loss: 0.09415320307016373\n",
      "\n",
      "Epoch : 115\n",
      " Time:16.0\n",
      "Generator Loss: 1.3592157363891602 Discriminator Loss: 0.36450210213661194\n",
      "\n",
      "Epoch : 116\n",
      " Time:16.0\n",
      "Generator Loss: 1.3716404438018799 Discriminator Loss: 0.43651145696640015\n",
      "\n",
      "Epoch : 117\n",
      " Time:16.0\n",
      "Generator Loss: 16.746135711669922 Discriminator Loss: 1.1367161273956299\n",
      "\n",
      "Epoch : 118\n",
      " Time:15.0\n",
      "Generator Loss: 1.5170135498046875 Discriminator Loss: 0.2710567116737366\n",
      "\n",
      "Epoch : 119\n",
      " Time:16.0\n",
      "Generator Loss: 5.445398330688477 Discriminator Loss: 0.005235901568084955\n",
      "\n",
      "Epoch : 120\n",
      " Time:16.0\n",
      "Generator Loss: 1.7097851037979126 Discriminator Loss: 0.24170246720314026\n",
      "\n",
      "Epoch : 121\n",
      " Time:16.0\n",
      "Generator Loss: 3.1477789878845215 Discriminator Loss: 0.04915080964565277\n",
      "\n",
      "Epoch : 122\n",
      " Time:16.0\n",
      "Generator Loss: 1.95914888381958 Discriminator Loss: 0.17286519706249237\n",
      "\n",
      "Epoch : 123\n",
      " Time:16.0\n",
      "Generator Loss: 2.2713308334350586 Discriminator Loss: 0.1571584790945053\n",
      "\n",
      "Epoch : 124\n",
      " Time:16.0\n",
      "Generator Loss: 2.291917562484741 Discriminator Loss: 0.15462513267993927\n",
      "\n",
      "Epoch : 125\n",
      " Time:16.0\n",
      "Generator Loss: 2.0612094402313232 Discriminator Loss: 0.25010165572166443\n",
      "\n",
      "Epoch : 126\n",
      " Time:16.0\n",
      "Generator Loss: 1.2439817190170288 Discriminator Loss: 0.4329872727394104\n",
      "\n",
      "Epoch : 127\n",
      " Time:16.0\n",
      "Generator Loss: 5.6625823974609375 Discriminator Loss: 2.2391583919525146\n",
      "\n",
      "Epoch : 128\n",
      " Time:16.0\n",
      "Generator Loss: 0.09621670842170715 Discriminator Loss: 2.6522960662841797\n",
      "\n",
      "Epoch : 129\n",
      " Time:16.0\n",
      "Generator Loss: 1.9739725589752197 Discriminator Loss: 0.17314119637012482\n",
      "\n",
      "Epoch : 130\n",
      " Time:16.0\n",
      "Generator Loss: 0.30971869826316833 Discriminator Loss: 1.4856932163238525\n",
      "\n",
      "Epoch : 131\n",
      " Time:16.0\n",
      "Generator Loss: 3.1553921699523926 Discriminator Loss: 0.06862754374742508\n",
      "\n",
      "Epoch : 132\n",
      " Time:16.0\n",
      "Generator Loss: 2.3381173610687256 Discriminator Loss: 0.1256292313337326\n",
      "\n",
      "Epoch : 133\n",
      " Time:16.0\n",
      "Generator Loss: 2.1955008506774902 Discriminator Loss: 0.17060405015945435\n",
      "\n",
      "Epoch : 134\n",
      " Time:16.0\n",
      "Generator Loss: 2.4251325130462646 Discriminator Loss: 0.16624195873737335\n",
      "\n",
      "Epoch : 135\n",
      " Time:16.0\n",
      "Generator Loss: 2.0739378929138184 Discriminator Loss: 0.19327694177627563\n",
      "\n",
      "Epoch : 136\n",
      " Time:16.0\n",
      "Generator Loss: 2.6018619537353516 Discriminator Loss: 0.17848776280879974\n",
      "\n",
      "Epoch : 137\n",
      " Time:16.0\n",
      "Generator Loss: 2.3139162063598633 Discriminator Loss: 0.13609813153743744\n",
      "\n",
      "Epoch : 138\n",
      " Time:16.0\n",
      "Generator Loss: 2.131727457046509 Discriminator Loss: 0.20841817557811737\n",
      "\n",
      "Epoch : 139\n",
      " Time:16.0\n",
      "Generator Loss: 2.50592303276062 Discriminator Loss: 0.30454009771347046\n",
      "\n",
      "Epoch : 140\n",
      " Time:16.0\n",
      "Generator Loss: 0.7351690530776978 Discriminator Loss: 0.8931434750556946\n",
      "\n",
      "Epoch : 141\n",
      " Time:16.0\n",
      "Generator Loss: 3.0649757385253906 Discriminator Loss: 0.7623330950737\n",
      "\n",
      "Epoch : 142\n",
      " Time:16.0\n",
      "Generator Loss: 0.20055577158927917 Discriminator Loss: 2.2014265060424805\n",
      "\n",
      "Epoch : 143\n",
      " Time:16.0\n",
      "Generator Loss: 2.2747411727905273 Discriminator Loss: 0.8111905455589294\n",
      "\n",
      "Epoch : 144\n",
      " Time:16.0\n",
      "Generator Loss: 1.1511166095733643 Discriminator Loss: 0.7256624102592468\n",
      "\n",
      "Epoch : 145\n",
      " Time:16.0\n",
      "Generator Loss: 3.1278772354125977 Discriminator Loss: 0.23286445438861847\n",
      "\n",
      "Epoch : 146\n",
      " Time:16.0\n",
      "Generator Loss: 6.957767486572266 Discriminator Loss: 0.03015880286693573\n",
      "\n",
      "Epoch : 147\n",
      " Time:16.0\n",
      "Generator Loss: 3.162276029586792 Discriminator Loss: 0.05685747414827347\n",
      "\n",
      "Epoch : 148\n",
      " Time:16.0\n",
      "Generator Loss: 1.9597654342651367 Discriminator Loss: 0.17833396792411804\n",
      "\n",
      "Epoch : 149\n",
      " Time:16.0\n",
      "Generator Loss: 1.8749332427978516 Discriminator Loss: 0.23775812983512878\n",
      "\n",
      "Epoch : 150\n",
      " Time:15.0\n",
      "Generator Loss: 2.1025123596191406 Discriminator Loss: 0.2673856019973755\n",
      "\n",
      "Epoch : 151\n",
      " Time:15.0\n",
      "Generator Loss: 2.9851622581481934 Discriminator Loss: 0.17837348580360413\n",
      "\n",
      "Epoch : 152\n",
      " Time:15.0\n",
      "Generator Loss: 2.0760698318481445 Discriminator Loss: 0.2240884006023407\n",
      "\n",
      "Epoch : 153\n",
      " Time:15.0\n",
      "Generator Loss: 2.3322057723999023 Discriminator Loss: 0.2518613934516907\n",
      "\n",
      "Epoch : 154\n",
      " Time:16.0\n",
      "Generator Loss: 3.2619762420654297 Discriminator Loss: 0.5492011904716492\n",
      "\n",
      "Epoch : 155\n",
      " Time:16.0\n",
      "Generator Loss: 0.07625842094421387 Discriminator Loss: 3.435365915298462\n",
      "\n",
      "Epoch : 156\n",
      " Time:16.0\n",
      "Generator Loss: 2.2035837173461914 Discriminator Loss: 0.2970580756664276\n",
      "\n",
      "Epoch : 157\n",
      " Time:16.0\n",
      "Generator Loss: 1.8454396724700928 Discriminator Loss: 0.3378390669822693\n",
      "\n",
      "Epoch : 158\n",
      " Time:16.0\n",
      "Generator Loss: 3.2760097980499268 Discriminator Loss: 0.15147335827350616\n",
      "\n",
      "Epoch : 159\n",
      " Time:16.0\n",
      "Generator Loss: 2.7855372428894043 Discriminator Loss: 0.08731130510568619\n",
      "\n",
      "Epoch : 160\n",
      " Time:16.0\n",
      "Generator Loss: 2.043731212615967 Discriminator Loss: 0.2342141568660736\n",
      "\n",
      "Epoch : 161\n",
      " Time:16.0\n",
      "Generator Loss: 4.289153099060059 Discriminator Loss: 0.6620479822158813\n",
      "\n",
      "Epoch : 162\n",
      " Time:16.0\n",
      "Generator Loss: 0.32048773765563965 Discriminator Loss: 1.6275330781936646\n",
      "\n",
      "Epoch : 163\n",
      " Time:17.0\n",
      "Generator Loss: 0.625922679901123 Discriminator Loss: 0.9932186603546143\n",
      "\n",
      "Epoch : 164\n",
      " Time:16.0\n",
      "Generator Loss: 1.434492588043213 Discriminator Loss: 0.4574747681617737\n",
      "\n",
      "Epoch : 165\n",
      " Time:17.0\n",
      "Generator Loss: 1.6240071058273315 Discriminator Loss: 0.25987935066223145\n",
      "\n",
      "Epoch : 166\n",
      " Time:16.0\n",
      "Generator Loss: 2.278223991394043 Discriminator Loss: 0.18351425230503082\n",
      "\n",
      "Epoch : 167\n",
      " Time:16.0\n",
      "Generator Loss: 1.6698577404022217 Discriminator Loss: 0.2812609374523163\n",
      "\n",
      "Epoch : 168\n",
      " Time:17.0\n",
      "Generator Loss: 2.7203495502471924 Discriminator Loss: 0.34308433532714844\n",
      "\n",
      "Epoch : 169\n",
      " Time:17.0\n",
      "Generator Loss: 1.7601189613342285 Discriminator Loss: 0.20594365894794464\n",
      "\n",
      "Epoch : 170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Time:16.0\n",
      "Generator Loss: 1.563118815422058 Discriminator Loss: 0.261070191860199\n",
      "\n",
      "Epoch : 171\n",
      " Time:16.0\n",
      "Generator Loss: 4.314167499542236 Discriminator Loss: 0.09988483786582947\n",
      "\n",
      "Epoch : 172\n",
      " Time:16.0\n",
      "Generator Loss: 3.2621030807495117 Discriminator Loss: 0.048724085092544556\n",
      "\n",
      "Epoch : 173\n",
      " Time:16.0\n",
      "Generator Loss: 3.3776402473449707 Discriminator Loss: 0.04677775502204895\n",
      "\n",
      "Epoch : 174\n",
      " Time:15.0\n",
      "Generator Loss: 3.7698311805725098 Discriminator Loss: 0.041390176862478256\n",
      "\n",
      "Epoch : 175\n",
      " Time:15.0\n",
      "Generator Loss: 7.478302001953125 Discriminator Loss: 0.011064577847719193\n",
      "\n",
      "Epoch : 176\n",
      " Time:15.0\n",
      "Generator Loss: 3.2158522605895996 Discriminator Loss: 0.05080273002386093\n",
      "\n",
      "Epoch : 177\n",
      " Time:15.0\n",
      "Generator Loss: 2.937757968902588 Discriminator Loss: 0.07803531736135483\n",
      "\n",
      "Epoch : 178\n",
      " Time:15.0\n",
      "Generator Loss: 2.306978225708008 Discriminator Loss: 0.1561993658542633\n",
      "\n",
      "Epoch : 179\n",
      " Time:16.0\n",
      "Generator Loss: 3.2325406074523926 Discriminator Loss: 0.3868609368801117\n",
      "\n",
      "Epoch : 180\n",
      " Time:16.0\n",
      "Generator Loss: 0.024006471037864685 Discriminator Loss: 4.01732063293457\n",
      "\n",
      "Epoch : 181\n",
      " Time:16.0\n",
      "Generator Loss: 4.653338432312012 Discriminator Loss: 0.22979864478111267\n",
      "\n",
      "Epoch : 182\n",
      " Time:16.0\n",
      "Generator Loss: 1.4542121887207031 Discriminator Loss: 0.2960660457611084\n",
      "\n",
      "Epoch : 183\n",
      " Time:16.0\n",
      "Generator Loss: 9.564189910888672 Discriminator Loss: 0.7221628427505493\n",
      "\n",
      "Epoch : 184\n",
      " Time:16.0\n",
      "Generator Loss: 1.4345910549163818 Discriminator Loss: 0.29123154282569885\n",
      "\n",
      "Epoch : 185\n",
      " Time:16.0\n",
      "Generator Loss: 1.6436076164245605 Discriminator Loss: 0.23899152874946594\n",
      "\n",
      "Epoch : 186\n",
      " Time:16.0\n",
      "Generator Loss: 2.2878787517547607 Discriminator Loss: 0.12777921557426453\n",
      "\n",
      "Epoch : 187\n",
      " Time:16.0\n",
      "Generator Loss: 1.6829661130905151 Discriminator Loss: 0.2774459719657898\n",
      "\n",
      "Epoch : 188\n",
      " Time:16.0\n",
      "Generator Loss: 2.9350831508636475 Discriminator Loss: 0.5109831094741821\n",
      "\n",
      "Epoch : 189\n",
      " Time:16.0\n",
      "Generator Loss: 0.5515848398208618 Discriminator Loss: 1.0054304599761963\n",
      "\n",
      "Epoch : 190\n",
      " Time:17.0\n",
      "Generator Loss: 4.509173393249512 Discriminator Loss: 0.46716150641441345\n",
      "\n",
      "Epoch : 191\n",
      " Time:16.0\n",
      "Generator Loss: 0.5288558006286621 Discriminator Loss: 0.9971283674240112\n",
      "\n",
      "Epoch : 192\n",
      " Time:16.0\n",
      "Generator Loss: 2.5697271823883057 Discriminator Loss: 0.11762558668851852\n",
      "\n",
      "Epoch : 193\n",
      " Time:17.0\n",
      "Generator Loss: 1.864003300666809 Discriminator Loss: 0.3210117816925049\n",
      "\n",
      "Epoch : 194\n",
      " Time:17.0\n",
      "Generator Loss: 3.552382707595825 Discriminator Loss: 0.2456096112728119\n",
      "\n",
      "Epoch : 195\n",
      " Time:17.0\n",
      "Generator Loss: 0.735816478729248 Discriminator Loss: 0.9429783225059509\n",
      "\n",
      "Epoch : 196\n",
      " Time:17.0\n",
      "Generator Loss: 4.230233192443848 Discriminator Loss: 1.0288039445877075\n",
      "\n",
      "Epoch : 197\n",
      " Time:17.0\n",
      "Generator Loss: 1.3721548318862915 Discriminator Loss: 0.36237388849258423\n",
      "\n",
      "Epoch : 198\n",
      " Time:16.0\n",
      "Generator Loss: 0.35305914282798767 Discriminator Loss: 1.7085340023040771\n",
      "\n",
      "Epoch : 199\n",
      " Time:16.0\n",
      "Generator Loss: 1.4925973415374756 Discriminator Loss: 0.6128745675086975\n",
      "\n",
      "Epoch : 200\n",
      " Time:16.0\n",
      "Generator Loss: 1.335660696029663 Discriminator Loss: 0.613203227519989\n",
      "\n",
      "Epoch : 201\n",
      " Time:15.0\n",
      "Generator Loss: 3.4894280433654785 Discriminator Loss: 0.5773297548294067\n",
      "\n",
      "Epoch : 202\n",
      " Time:14.0\n",
      "Generator Loss: 0.577278733253479 Discriminator Loss: 1.2954866886138916\n",
      "\n",
      "Epoch : 203\n",
      " Time:14.0\n",
      "Generator Loss: 2.4276185035705566 Discriminator Loss: 0.21794897317886353\n",
      "\n",
      "Epoch : 204\n",
      " Time:15.0\n",
      "Generator Loss: 1.770746111869812 Discriminator Loss: 0.27262258529663086\n",
      "\n",
      "Epoch : 205\n",
      " Time:15.0\n",
      "Generator Loss: 1.8843810558319092 Discriminator Loss: 0.33153846859931946\n",
      "\n",
      "Epoch : 206\n",
      " Time:15.0\n",
      "Generator Loss: 2.0565290451049805 Discriminator Loss: 0.33795201778411865\n",
      "\n",
      "Epoch : 207\n",
      " Time:15.0\n",
      "Generator Loss: 1.7235157489776611 Discriminator Loss: 0.4751463830471039\n",
      "\n",
      "Epoch : 208\n",
      " Time:14.0\n",
      "Generator Loss: 5.7264299392700195 Discriminator Loss: 1.5853619575500488\n",
      "\n",
      "Epoch : 209\n",
      " Time:15.0\n",
      "Generator Loss: 0.9165903329849243 Discriminator Loss: 0.5411778092384338\n",
      "\n",
      "Epoch : 210\n",
      " Time:15.0\n",
      "Generator Loss: 0.8928881287574768 Discriminator Loss: 0.650393009185791\n",
      "\n",
      "Epoch : 211\n",
      " Time:15.0\n",
      "Generator Loss: 1.3095855712890625 Discriminator Loss: 0.9547198414802551\n",
      "\n",
      "Epoch : 212\n",
      " Time:14.0\n",
      "Generator Loss: 2.9146132469177246 Discriminator Loss: 1.0201693773269653\n",
      "\n",
      "Epoch : 213\n",
      " Time:14.0\n",
      "Generator Loss: 1.739580750465393 Discriminator Loss: 0.20702695846557617\n",
      "\n",
      "Epoch : 214\n",
      " Time:14.0\n",
      "Generator Loss: 1.452344536781311 Discriminator Loss: 0.32900547981262207\n",
      "\n",
      "Epoch : 215\n",
      " Time:15.0\n",
      "Generator Loss: 1.955191731452942 Discriminator Loss: 0.3106043338775635\n",
      "\n",
      "Epoch : 216\n",
      " Time:15.0\n",
      "Generator Loss: 2.3625354766845703 Discriminator Loss: 0.27986961603164673\n",
      "\n",
      "Epoch : 217\n",
      " Time:15.0\n",
      "Generator Loss: 1.7740877866744995 Discriminator Loss: 0.30405178666114807\n",
      "\n",
      "Epoch : 218\n",
      " Time:15.0\n",
      "Generator Loss: 3.7910513877868652 Discriminator Loss: 0.37868866324424744\n",
      "\n",
      "Epoch : 219\n",
      " Time:14.0\n",
      "Generator Loss: 1.385878562927246 Discriminator Loss: 0.30656805634498596\n",
      "\n",
      "Epoch : 220\n",
      " Time:15.0\n",
      "Generator Loss: 1.2696787118911743 Discriminator Loss: 0.3846278488636017\n",
      "\n",
      "Epoch : 221\n",
      " Time:15.0\n",
      "Generator Loss: 1.7754294872283936 Discriminator Loss: 0.31602272391319275\n",
      "\n",
      "Epoch : 222\n",
      " Time:14.0\n",
      "Generator Loss: 4.469760894775391 Discriminator Loss: 0.6316945552825928\n",
      "\n",
      "Epoch : 223\n",
      " Time:14.0\n",
      "Generator Loss: 0.45622745156288147 Discriminator Loss: 1.211870551109314\n",
      "\n",
      "Epoch : 224\n",
      " Time:15.0\n",
      "Generator Loss: 1.0285189151763916 Discriminator Loss: 0.7081537842750549\n",
      "\n",
      "Epoch : 225\n",
      " Time:15.0\n",
      "Generator Loss: 3.870858907699585 Discriminator Loss: 0.7626730799674988\n",
      "\n",
      "Epoch : 226\n",
      " Time:14.0\n",
      "Generator Loss: 0.7450548410415649 Discriminator Loss: 0.7255305647850037\n",
      "\n",
      "Epoch : 227\n",
      " Time:14.0\n",
      "Generator Loss: 1.5304651260375977 Discriminator Loss: 0.326486736536026\n",
      "\n",
      "Epoch : 228\n",
      " Time:14.0\n",
      "Generator Loss: 2.2368969917297363 Discriminator Loss: 0.2836514413356781\n",
      "\n",
      "Epoch : 229\n",
      " Time:14.0\n",
      "Generator Loss: 3.8782825469970703 Discriminator Loss: 0.06589561700820923\n",
      "\n",
      "Epoch : 230\n",
      " Time:14.0\n",
      "Generator Loss: 3.100147247314453 Discriminator Loss: 0.10457593202590942\n",
      "\n",
      "Epoch : 231\n",
      " Time:15.0\n",
      "Generator Loss: 2.7787868976593018 Discriminator Loss: 0.11571747809648514\n",
      "\n",
      "Epoch : 232\n",
      " Time:14.0\n",
      "Generator Loss: 2.428457736968994 Discriminator Loss: 0.187461256980896\n",
      "\n",
      "Epoch : 233\n",
      " Time:15.0\n",
      "Generator Loss: 3.026663303375244 Discriminator Loss: 0.1952086091041565\n",
      "\n",
      "Epoch : 234\n",
      " Time:14.0\n",
      "Generator Loss: 1.3025128841400146 Discriminator Loss: 0.40615397691726685\n",
      "\n",
      "Epoch : 235\n",
      " Time:15.0\n",
      "Generator Loss: 4.393621444702148 Discriminator Loss: 1.43681001663208\n",
      "\n",
      "Epoch : 236\n",
      " Time:15.0\n",
      "Generator Loss: 0.07068023830652237 Discriminator Loss: 3.2780988216400146\n",
      "\n",
      "Epoch : 237\n",
      " Time:14.0\n",
      "Generator Loss: 0.8638008832931519 Discriminator Loss: 0.6734654307365417\n",
      "\n",
      "Epoch : 238\n",
      " Time:14.0\n",
      "Generator Loss: 0.5919253826141357 Discriminator Loss: 1.1070836782455444\n",
      "\n",
      "Epoch : 239\n",
      " Time:14.0\n",
      "Generator Loss: 0.9809856414794922 Discriminator Loss: 0.6378374099731445\n",
      "\n",
      "Epoch : 240\n",
      " Time:15.0\n",
      "Generator Loss: 1.3612079620361328 Discriminator Loss: 0.43762606382369995\n",
      "\n",
      "Epoch : 241\n",
      " Time:15.0\n",
      "Generator Loss: 1.7400985956192017 Discriminator Loss: 0.32463520765304565\n",
      "\n",
      "Epoch : 242\n",
      " Time:15.0\n",
      "Generator Loss: 1.885746717453003 Discriminator Loss: 0.2753849923610687\n",
      "\n",
      "Epoch : 243\n",
      " Time:14.0\n",
      "Generator Loss: 2.2190475463867188 Discriminator Loss: 0.2364267110824585\n",
      "\n",
      "Epoch : 244\n",
      " Time:14.0\n",
      "Generator Loss: 2.8996357917785645 Discriminator Loss: 0.10194559395313263\n",
      "\n",
      "Epoch : 245\n",
      " Time:14.0\n",
      "Generator Loss: 2.2135519981384277 Discriminator Loss: 0.2817889451980591\n",
      "\n",
      "Epoch : 246\n",
      " Time:14.0\n",
      "Generator Loss: 2.880143642425537 Discriminator Loss: 0.7145633101463318\n",
      "\n",
      "Epoch : 247\n",
      " Time:14.0\n",
      "Generator Loss: 1.156597375869751 Discriminator Loss: 0.441325843334198\n",
      "\n",
      "Epoch : 248\n",
      " Time:15.0\n",
      "Generator Loss: 1.7205902338027954 Discriminator Loss: 0.2839661240577698\n",
      "\n",
      "Epoch : 249\n",
      " Time:15.0\n",
      "Generator Loss: 1.8826454877853394 Discriminator Loss: 0.6206709146499634\n",
      "\n",
      "Epoch : 250\n",
      " Time:14.0\n",
      "Generator Loss: 11.986096382141113 Discriminator Loss: 0.0883563905954361\n",
      "\n",
      "Epoch : 251\n",
      " Time:14.0\n",
      "Generator Loss: 3.4314658641815186 Discriminator Loss: 0.043553002178668976\n",
      "\n",
      "Epoch : 252\n",
      " Time:14.0\n",
      "Generator Loss: 2.0426254272460938 Discriminator Loss: 0.2353040724992752\n",
      "\n",
      "Epoch : 253\n",
      " Time:14.0\n",
      "Generator Loss: 3.9860963821411133 Discriminator Loss: 0.29932737350463867\n",
      "\n",
      "Epoch : 254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Time:14.0\n",
      "Generator Loss: 1.8351941108703613 Discriminator Loss: 0.42282673716545105\n",
      "\n",
      "Epoch : 255\n",
      " Time:15.0\n",
      "Generator Loss: 2.323528528213501 Discriminator Loss: 0.2703213691711426\n",
      "\n",
      "Epoch : 256\n",
      " Time:15.0\n",
      "Generator Loss: 2.758823871612549 Discriminator Loss: 0.22713059186935425\n",
      "\n",
      "Epoch : 257\n",
      " Time:14.0\n",
      "Generator Loss: 1.719761610031128 Discriminator Loss: 0.35347965359687805\n",
      "\n",
      "Epoch : 258\n",
      " Time:14.0\n",
      "Generator Loss: 5.0823822021484375 Discriminator Loss: 0.8120875358581543\n",
      "\n",
      "Epoch : 259\n",
      " Time:14.0\n",
      "Generator Loss: 0.2487906664609909 Discriminator Loss: 1.9415535926818848\n",
      "\n",
      "Epoch : 260\n",
      " Time:15.0\n",
      "Generator Loss: 1.7701807022094727 Discriminator Loss: 0.2550177574157715\n",
      "\n",
      "Epoch : 261\n",
      " Time:15.0\n",
      "Generator Loss: 1.9087975025177002 Discriminator Loss: 0.3060341477394104\n",
      "\n",
      "Epoch : 262\n",
      " Time:15.0\n",
      "Generator Loss: 2.6870317459106445 Discriminator Loss: 0.2933341860771179\n",
      "\n",
      "Epoch : 263\n",
      " Time:14.0\n",
      "Generator Loss: 1.7810003757476807 Discriminator Loss: 0.26296260952949524\n",
      "\n",
      "Epoch : 264\n",
      " Time:15.0\n",
      "Generator Loss: 3.165466070175171 Discriminator Loss: 0.12670542299747467\n",
      "\n",
      "Epoch : 265\n",
      " Time:15.0\n",
      "Generator Loss: 3.102468967437744 Discriminator Loss: 0.07448926568031311\n",
      "\n",
      "Epoch : 266\n",
      " Time:14.0\n",
      "Generator Loss: 4.550802707672119 Discriminator Loss: 0.03819417580962181\n",
      "\n",
      "Epoch : 267\n",
      " Time:15.0\n",
      "Generator Loss: 3.3442866802215576 Discriminator Loss: 0.05877268314361572\n",
      "\n",
      "Epoch : 268\n",
      " Time:14.0\n",
      "Generator Loss: 3.8781652450561523 Discriminator Loss: 0.05156981945037842\n",
      "\n",
      "Epoch : 269\n",
      " Time:14.0\n",
      "Generator Loss: 3.3571441173553467 Discriminator Loss: 0.0531967431306839\n",
      "\n",
      "Epoch : 270\n",
      " Time:14.0\n",
      "Generator Loss: 3.001323699951172 Discriminator Loss: 0.08563224971294403\n",
      "\n",
      "Epoch : 271\n",
      " Time:15.0\n",
      "Generator Loss: 3.9845733642578125 Discriminator Loss: 0.07779669016599655\n",
      "\n",
      "Epoch : 272\n",
      " Time:14.0\n",
      "Generator Loss: 2.537510395050049 Discriminator Loss: 0.14260897040367126\n",
      "\n",
      "Epoch : 273\n",
      " Time:14.0\n",
      "Generator Loss: 4.67683219909668 Discriminator Loss: 0.6641313433647156\n",
      "\n",
      "Epoch : 274\n",
      " Time:15.0\n",
      "Generator Loss: 0.04624750465154648 Discriminator Loss: 3.694859266281128\n",
      "\n",
      "Epoch : 275\n",
      " Time:14.0\n",
      "Generator Loss: 2.829946279525757 Discriminator Loss: 0.13990317285060883\n",
      "\n",
      "Epoch : 276\n",
      " Time:15.0\n",
      "Generator Loss: 1.316666603088379 Discriminator Loss: 0.33590707182884216\n",
      "\n",
      "Epoch : 277\n",
      " Time:15.0\n",
      "Generator Loss: 1.9612926244735718 Discriminator Loss: 0.2592703104019165\n",
      "\n",
      "Epoch : 278\n",
      " Time:15.0\n",
      "Generator Loss: 2.0797905921936035 Discriminator Loss: 0.15770965814590454\n",
      "\n",
      "Epoch : 279\n",
      " Time:14.0\n",
      "Generator Loss: 3.6890196800231934 Discriminator Loss: 0.067414790391922\n",
      "\n",
      "Epoch : 280\n",
      " Time:14.0\n",
      "Generator Loss: 3.4973788261413574 Discriminator Loss: 0.04723580926656723\n",
      "\n",
      "Epoch : 281\n",
      " Time:14.0\n",
      "Generator Loss: 2.8325939178466797 Discriminator Loss: 0.09525971114635468\n",
      "\n",
      "Epoch : 282\n",
      " Time:15.0\n",
      "Generator Loss: 3.088862895965576 Discriminator Loss: 0.12850818037986755\n",
      "\n",
      "Epoch : 283\n",
      " Time:15.0\n",
      "Generator Loss: 3.2772650718688965 Discriminator Loss: 0.07603023201227188\n",
      "\n",
      "Epoch : 284\n",
      " Time:15.0\n",
      "Generator Loss: 3.994636058807373 Discriminator Loss: 0.06566727161407471\n",
      "\n",
      "Epoch : 285\n",
      " Time:14.0\n",
      "Generator Loss: 2.4354052543640137 Discriminator Loss: 0.12986499071121216\n",
      "\n",
      "Epoch : 286\n",
      " Time:15.0\n",
      "Generator Loss: 3.7935237884521484 Discriminator Loss: 0.19211120903491974\n",
      "\n",
      "Epoch : 287\n",
      " Time:15.0\n",
      "Generator Loss: 0.5417466759681702 Discriminator Loss: 1.1982072591781616\n",
      "\n",
      "Epoch : 288\n",
      " Time:15.0\n",
      "Generator Loss: 9.514629364013672 Discriminator Loss: 6.573648929595947\n",
      "\n",
      "Epoch : 289\n",
      " Time:15.0\n",
      "Generator Loss: 0.7515197992324829 Discriminator Loss: 0.6618444919586182\n",
      "\n",
      "Epoch : 290\n",
      " Time:14.0\n",
      "Generator Loss: 1.213974118232727 Discriminator Loss: 0.3759464919567108\n",
      "\n",
      "Epoch : 291\n",
      " Time:15.0\n",
      "Generator Loss: 1.699284315109253 Discriminator Loss: 0.22782869637012482\n",
      "\n",
      "Epoch : 292\n",
      " Time:14.0\n",
      "Generator Loss: 2.3694956302642822 Discriminator Loss: 0.11639238148927689\n",
      "\n",
      "Epoch : 293\n",
      " Time:15.0\n",
      "Generator Loss: 4.690518379211426 Discriminator Loss: 0.042268503457307816\n",
      "\n",
      "Epoch : 294\n",
      " Time:15.0\n",
      "Generator Loss: 2.506932258605957 Discriminator Loss: 0.09964094310998917\n",
      "\n",
      "Epoch : 295\n",
      " Time:15.0\n",
      "Generator Loss: 2.0269899368286133 Discriminator Loss: 0.1803208291530609\n",
      "\n",
      "Epoch : 296\n",
      " Time:15.0\n",
      "Generator Loss: 2.6749000549316406 Discriminator Loss: 0.22271299362182617\n",
      "\n",
      "Epoch : 297\n",
      " Time:14.0\n",
      "Generator Loss: 1.45048987865448 Discriminator Loss: 0.414549320936203\n",
      "\n",
      "Epoch : 298\n",
      " Time:15.0\n",
      "Generator Loss: 2.578902244567871 Discriminator Loss: 0.14664971828460693\n",
      "\n",
      "Epoch : 299\n",
      " Time:14.0\n",
      "Generator Loss: 2.4035274982452393 Discriminator Loss: 0.17412714660167694\n",
      "\n",
      "Epoch : 300\n",
      " Time:15.0\n",
      "Generator Loss: 3.236837863922119 Discriminator Loss: 0.1551899015903473\n",
      "\n",
      "Epoch : 301\n",
      " Time:15.0\n",
      "Generator Loss: 5.449234962463379 Discriminator Loss: 0.8103044033050537\n",
      "\n",
      "Epoch : 302\n",
      " Time:14.0\n",
      "Generator Loss: 4.8293304443359375 Discriminator Loss: 0.09423848241567612\n",
      "\n",
      "Epoch : 303\n",
      " Time:14.0\n",
      "Generator Loss: 2.248595714569092 Discriminator Loss: 0.2264283448457718\n",
      "\n",
      "Epoch : 304\n",
      " Time:15.0\n",
      "Generator Loss: 3.4743919372558594 Discriminator Loss: 0.09889981150627136\n",
      "\n",
      "Epoch : 305\n",
      " Time:14.0\n",
      "Generator Loss: 3.3767547607421875 Discriminator Loss: 0.06708741933107376\n",
      "\n",
      "Epoch : 306\n",
      " Time:15.0\n",
      "Generator Loss: 4.041155815124512 Discriminator Loss: 0.04572613537311554\n",
      "\n",
      "Epoch : 307\n",
      " Time:15.0\n",
      "Generator Loss: 3.4152212142944336 Discriminator Loss: 0.0630272924900055\n",
      "\n",
      "Epoch : 308\n",
      " Time:15.0\n",
      "Generator Loss: 4.4722394943237305 Discriminator Loss: 0.04876992106437683\n",
      "\n",
      "Epoch : 309\n",
      " Time:14.0\n",
      "Generator Loss: 4.003170967102051 Discriminator Loss: 0.03184312582015991\n",
      "\n",
      "Epoch : 310\n",
      " Time:15.0\n",
      "Generator Loss: 3.1888532638549805 Discriminator Loss: 0.0770321786403656\n",
      "\n",
      "Epoch : 311\n",
      " Time:14.0\n",
      "Generator Loss: 3.9821574687957764 Discriminator Loss: 0.12492509186267853\n",
      "\n",
      "Epoch : 312\n",
      " Time:14.0\n",
      "Generator Loss: 1.083446741104126 Discriminator Loss: 0.6386730074882507\n",
      "\n",
      "Epoch : 313\n",
      " Time:14.0\n",
      "Generator Loss: 7.150618076324463 Discriminator Loss: 2.6038753986358643\n",
      "\n",
      "Epoch : 314\n",
      " Time:15.0\n",
      "Generator Loss: 0.229399636387825 Discriminator Loss: 1.7738008499145508\n",
      "\n",
      "Epoch : 315\n",
      " Time:14.0\n",
      "Generator Loss: 2.2280807495117188 Discriminator Loss: 0.15969830751419067\n",
      "\n",
      "Epoch : 316\n",
      " Time:15.0\n",
      "Generator Loss: 1.1885160207748413 Discriminator Loss: 0.9039302468299866\n",
      "\n",
      "Epoch : 317\n",
      " Time:14.0\n",
      "Generator Loss: 2.4458260536193848 Discriminator Loss: 0.5325742363929749\n",
      "\n",
      "Epoch : 318\n",
      " Time:14.0\n",
      "Generator Loss: 0.943271815776825 Discriminator Loss: 0.68961501121521\n",
      "\n",
      "Epoch : 319\n",
      " Time:15.0\n",
      "Generator Loss: 2.6210451126098633 Discriminator Loss: 0.15063709020614624\n",
      "\n",
      "Epoch : 320\n",
      " Time:15.0\n",
      "Generator Loss: 2.692964553833008 Discriminator Loss: 0.17087876796722412\n",
      "\n",
      "Epoch : 321\n",
      " Time:14.0\n",
      "Generator Loss: 3.9101665019989014 Discriminator Loss: 0.10429248213768005\n",
      "\n",
      "Epoch : 322\n",
      " Time:14.0\n",
      "Generator Loss: 3.571699619293213 Discriminator Loss: 0.05784759670495987\n",
      "\n",
      "Epoch : 323\n",
      " Time:14.0\n",
      "Generator Loss: 2.7292628288269043 Discriminator Loss: 0.10333957523107529\n",
      "\n",
      "Epoch : 324\n",
      " Time:15.0\n",
      "Generator Loss: 4.668725967407227 Discriminator Loss: 0.07180509716272354\n",
      "\n",
      "Epoch : 325\n",
      " Time:15.0\n",
      "Generator Loss: 4.500964164733887 Discriminator Loss: 0.018126823008060455\n",
      "\n",
      "Epoch : 326\n",
      " Time:15.0\n",
      "Generator Loss: 3.5114569664001465 Discriminator Loss: 0.04309022054076195\n",
      "\n",
      "Epoch : 327\n",
      " Time:15.0\n",
      "Generator Loss: 3.281073808670044 Discriminator Loss: 0.07198607921600342\n",
      "\n",
      "Epoch : 328\n",
      " Time:15.0\n",
      "Generator Loss: 4.6560258865356445 Discriminator Loss: 0.046700410544872284\n",
      "\n",
      "Epoch : 329\n",
      " Time:15.0\n",
      "Generator Loss: 4.190845489501953 Discriminator Loss: 0.02916743978857994\n",
      "\n",
      "Epoch : 330\n",
      " Time:15.0\n",
      "Generator Loss: 4.158082962036133 Discriminator Loss: 0.032242774963378906\n",
      "\n",
      "Epoch : 331\n",
      " Time:14.0\n",
      "Generator Loss: 4.328527927398682 Discriminator Loss: 0.029760349541902542\n",
      "\n",
      "Epoch : 332\n",
      " Time:15.0\n",
      "Generator Loss: 3.5794267654418945 Discriminator Loss: 0.05429716035723686\n",
      "\n",
      "Epoch : 333\n",
      " Time:14.0\n",
      "Generator Loss: 4.041931629180908 Discriminator Loss: 0.07923057675361633\n",
      "\n",
      "Epoch : 334\n",
      " Time:15.0\n",
      "Generator Loss: 2.001671552658081 Discriminator Loss: 0.23409901559352875\n",
      "\n",
      "Epoch : 335\n",
      " Time:14.0\n",
      "Generator Loss: 7.682910919189453 Discriminator Loss: 1.4139783382415771\n",
      "\n",
      "Epoch : 336\n",
      " Time:15.0\n",
      "Generator Loss: 0.18518216907978058 Discriminator Loss: 2.0217607021331787\n",
      "\n",
      "Epoch : 337\n",
      " Time:14.0\n",
      "Generator Loss: 6.119938373565674 Discriminator Loss: 0.5994324088096619\n",
      "\n",
      "Epoch : 338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Time:14.0\n",
      "Generator Loss: 0.8770225048065186 Discriminator Loss: 0.7530056238174438\n",
      "\n",
      "Epoch : 339\n",
      " Time:15.0\n",
      "Generator Loss: 1.8840811252593994 Discriminator Loss: 0.22840219736099243\n",
      "\n",
      "Epoch : 340\n",
      " Time:14.0\n",
      "Generator Loss: 2.2970852851867676 Discriminator Loss: 0.1579817831516266\n",
      "\n",
      "Epoch : 341\n",
      " Time:15.0\n",
      "Generator Loss: 2.884392261505127 Discriminator Loss: 0.09538181126117706\n",
      "\n",
      "Epoch : 342\n",
      " Time:15.0\n",
      "Generator Loss: 2.937574863433838 Discriminator Loss: 0.08048111200332642\n",
      "\n",
      "Epoch : 343\n",
      " Time:15.0\n",
      "Generator Loss: 4.0832414627075195 Discriminator Loss: 0.041548050940036774\n",
      "\n",
      "Epoch : 344\n",
      " Time:15.0\n",
      "Generator Loss: 4.547548294067383 Discriminator Loss: 0.02136717364192009\n",
      "\n",
      "Epoch : 345\n",
      " Time:15.0\n",
      "Generator Loss: 4.165289878845215 Discriminator Loss: 0.034820184111595154\n",
      "\n",
      "Epoch : 346\n",
      " Time:14.0\n",
      "Generator Loss: 3.7946481704711914 Discriminator Loss: 0.06642679870128632\n",
      "\n",
      "Epoch : 347\n",
      " Time:14.0\n",
      "Generator Loss: 3.695136070251465 Discriminator Loss: 0.1148817166686058\n",
      "\n",
      "Epoch : 348\n",
      " Time:14.0\n",
      "Generator Loss: 3.0154004096984863 Discriminator Loss: 0.1345694214105606\n",
      "\n",
      "Epoch : 349\n",
      " Time:15.0\n",
      "Generator Loss: 4.4062418937683105 Discriminator Loss: 0.07398068904876709\n",
      "\n",
      "Epoch : 350\n",
      " Time:15.0\n",
      "Generator Loss: 3.2524707317352295 Discriminator Loss: 0.23168663680553436\n",
      "\n",
      "Epoch : 351\n",
      " Time:15.0\n",
      "Generator Loss: 4.791374206542969 Discriminator Loss: 0.8747825026512146\n",
      "\n",
      "Epoch : 352\n",
      " Time:14.0\n",
      "Generator Loss: 1.35160231590271 Discriminator Loss: 1.1150645017623901\n",
      "\n",
      "Epoch : 353\n",
      " Time:14.0\n",
      "Generator Loss: 4.8364362716674805 Discriminator Loss: 0.3269861042499542\n",
      "\n",
      "Epoch : 354\n",
      " Time:14.0\n",
      "Generator Loss: 0.5985009670257568 Discriminator Loss: 1.4227945804595947\n",
      "\n",
      "Epoch : 355\n",
      " Time:15.0\n",
      "Generator Loss: 6.439881324768066 Discriminator Loss: 0.48911571502685547\n",
      "\n",
      "Epoch : 356\n",
      " Time:15.0\n",
      "Generator Loss: 2.752084255218506 Discriminator Loss: 0.07984746247529984\n",
      "\n",
      "Epoch : 357\n",
      " Time:15.0\n",
      "Generator Loss: 1.9452276229858398 Discriminator Loss: 0.2634512484073639\n",
      "\n",
      "Epoch : 358\n",
      " Time:15.0\n",
      "Generator Loss: 4.196210861206055 Discriminator Loss: 0.039325322955846786\n",
      "\n",
      "Epoch : 359\n",
      " Time:15.0\n",
      "Generator Loss: 3.466684341430664 Discriminator Loss: 0.058633700013160706\n",
      "\n",
      "Epoch : 360\n",
      " Time:14.0\n",
      "Generator Loss: 4.23316764831543 Discriminator Loss: 0.051881179213523865\n",
      "\n",
      "Epoch : 361\n",
      " Time:15.0\n",
      "Generator Loss: 4.725264549255371 Discriminator Loss: 0.029908007010817528\n",
      "\n",
      "Epoch : 362\n",
      " Time:14.0\n",
      "Generator Loss: 5.154236793518066 Discriminator Loss: 0.01667157933115959\n",
      "\n",
      "Epoch : 363\n",
      " Time:14.0\n",
      "Generator Loss: 3.696469783782959 Discriminator Loss: 0.06708081066608429\n",
      "\n",
      "Epoch : 364\n",
      " Time:15.0\n",
      "Generator Loss: 3.9335429668426514 Discriminator Loss: 0.12456870824098587\n",
      "\n",
      "Epoch : 365\n",
      " Time:15.0\n",
      "Generator Loss: 2.204078197479248 Discriminator Loss: 0.2176865041255951\n",
      "\n",
      "Epoch : 366\n",
      " Time:15.0\n",
      "Generator Loss: 5.88463020324707 Discriminator Loss: 0.19879406690597534\n",
      "\n",
      "Epoch : 367\n",
      " Time:15.0\n",
      "Generator Loss: 1.7086318731307983 Discriminator Loss: 0.32628771662712097\n",
      "\n",
      "Epoch : 368\n",
      " Time:14.0\n",
      "Generator Loss: 3.977292060852051 Discriminator Loss: 0.17178122699260712\n",
      "\n",
      "Epoch : 369\n",
      " Time:14.0\n",
      "Generator Loss: 1.5311338901519775 Discriminator Loss: 0.410942018032074\n",
      "\n",
      "Epoch : 370\n",
      " Time:14.0\n",
      "Generator Loss: 7.172019958496094 Discriminator Loss: 1.00734543800354\n",
      "\n",
      "Epoch : 371\n",
      " Time:14.0\n",
      "Generator Loss: 0.2973812520503998 Discriminator Loss: 1.8485009670257568\n",
      "\n",
      "Epoch : 372\n",
      " Time:14.0\n",
      "Generator Loss: 3.748889207839966 Discriminator Loss: 1.0283340215682983\n",
      "\n",
      "Epoch : 373\n",
      " Time:15.0\n",
      "Generator Loss: 2.677140712738037 Discriminator Loss: 0.09954612702131271\n",
      "\n",
      "Epoch : 374\n",
      " Time:14.0\n",
      "Generator Loss: 1.406672477722168 Discriminator Loss: 0.42440518736839294\n",
      "\n",
      "Epoch : 375\n",
      " Time:15.0\n",
      "Generator Loss: 3.899595260620117 Discriminator Loss: 0.07771585136651993\n",
      "\n",
      "Epoch : 376\n",
      " Time:14.0\n",
      "Generator Loss: 2.5749125480651855 Discriminator Loss: 0.15044957399368286\n",
      "\n",
      "Epoch : 377\n",
      " Time:15.0\n",
      "Generator Loss: 5.555386543273926 Discriminator Loss: 0.06893131136894226\n",
      "\n",
      "Epoch : 378\n",
      " Time:14.0\n",
      "Generator Loss: 6.478899955749512 Discriminator Loss: 0.007018955424427986\n",
      "\n",
      "Epoch : 379\n",
      " Time:14.0\n",
      "Generator Loss: 3.9877233505249023 Discriminator Loss: 0.04668042063713074\n",
      "\n",
      "Epoch : 380\n",
      " Time:15.0\n",
      "Generator Loss: 4.190961837768555 Discriminator Loss: 0.028445325791835785\n",
      "\n",
      "Epoch : 381\n",
      " Time:14.0\n",
      "Generator Loss: 5.732962608337402 Discriminator Loss: 0.016247544437646866\n",
      "\n",
      "Epoch : 382\n",
      " Time:15.0\n",
      "Generator Loss: 4.341483116149902 Discriminator Loss: 0.02415069006383419\n",
      "\n",
      "Epoch : 383\n",
      " Time:15.0\n",
      "Generator Loss: 5.426333427429199 Discriminator Loss: 0.014867475256323814\n",
      "\n",
      "Epoch : 384\n",
      " Time:15.0\n",
      "Generator Loss: 3.2150607109069824 Discriminator Loss: 0.0724157840013504\n",
      "\n",
      "Epoch : 385\n",
      " Time:14.0\n",
      "Generator Loss: 5.806783676147461 Discriminator Loss: 0.2782338857650757\n",
      "\n",
      "Epoch : 386\n",
      " Time:14.0\n",
      "Generator Loss: 0.29265493154525757 Discriminator Loss: 1.7795330286026\n",
      "\n",
      "Epoch : 387\n",
      " Time:14.0\n",
      "Generator Loss: 9.033103942871094 Discriminator Loss: 3.75937819480896\n",
      "\n",
      "Epoch : 388\n",
      " Time:14.0\n",
      "Generator Loss: 2.4140853881835938 Discriminator Loss: 0.10240118205547333\n",
      "\n",
      "Epoch : 389\n",
      " Time:14.0\n",
      "Generator Loss: 1.9286317825317383 Discriminator Loss: 0.19500558078289032\n",
      "\n",
      "Epoch : 390\n",
      " Time:15.0\n",
      "Generator Loss: 3.74180006980896 Discriminator Loss: 0.061923954635858536\n",
      "\n",
      "Epoch : 391\n",
      " Time:15.0\n",
      "Generator Loss: 3.986769199371338 Discriminator Loss: 0.07251816987991333\n",
      "\n",
      "Epoch : 392\n",
      " Time:15.0\n",
      "Generator Loss: 3.480278968811035 Discriminator Loss: 0.05822326987981796\n",
      "\n",
      "Epoch : 393\n",
      " Time:15.0\n",
      "Generator Loss: 4.127820014953613 Discriminator Loss: 0.07186873257160187\n",
      "\n",
      "Epoch : 394\n",
      " Time:14.0\n",
      "Generator Loss: 5.376219749450684 Discriminator Loss: 0.018938075751066208\n",
      "\n",
      "Epoch : 395\n",
      " Time:15.0\n",
      "Generator Loss: 5.288638114929199 Discriminator Loss: 0.013102386146783829\n",
      "\n",
      "Epoch : 396\n",
      " Time:15.0\n",
      "Generator Loss: 3.6998555660247803 Discriminator Loss: 0.044415418058633804\n",
      "\n",
      "Epoch : 397\n",
      " Time:14.0\n",
      "Generator Loss: 4.808860778808594 Discriminator Loss: 0.04275219514966011\n",
      "\n",
      "Epoch : 398\n",
      " Time:15.0\n",
      "Generator Loss: 3.654226779937744 Discriminator Loss: 0.04189801588654518\n",
      "\n",
      "Epoch : 399\n",
      " Time:14.0\n",
      "Generator Loss: 4.768880844116211 Discriminator Loss: 0.03735920786857605\n",
      "\n",
      "Epoch : 400\n",
      " Time:14.0\n",
      "Generator Loss: 4.997254848480225 Discriminator Loss: 0.0309919286519289\n",
      "\n",
      "Epoch : 401\n",
      " Time:15.0\n",
      "Generator Loss: 2.95957350730896 Discriminator Loss: 0.09921518713235855\n",
      "\n",
      "Epoch : 402\n",
      " Time:14.0\n",
      "Generator Loss: 8.0318603515625 Discriminator Loss: 1.16885507106781\n",
      "\n",
      "Epoch : 403\n",
      " Time:15.0\n",
      "Generator Loss: 0.120309017598629 Discriminator Loss: 2.7424399852752686\n",
      "\n",
      "Epoch : 404\n",
      " Time:14.0\n",
      "Generator Loss: 4.775570392608643 Discriminator Loss: 0.5458720326423645\n",
      "\n",
      "Epoch : 405\n",
      " Time:14.0\n",
      "Generator Loss: 1.1988493204116821 Discriminator Loss: 0.5867647528648376\n",
      "\n",
      "Epoch : 406\n",
      " Time:15.0\n",
      "Generator Loss: 3.265349864959717 Discriminator Loss: 0.09495760500431061\n",
      "\n",
      "Epoch : 407\n",
      " Time:15.0\n",
      "Generator Loss: 2.795292854309082 Discriminator Loss: 0.14022117853164673\n",
      "\n",
      "Epoch : 408\n",
      " Time:15.0\n",
      "Generator Loss: 3.3441576957702637 Discriminator Loss: 0.12123432755470276\n",
      "\n",
      "Epoch : 409\n",
      " Time:14.0\n",
      "Generator Loss: 2.3353261947631836 Discriminator Loss: 0.16939933598041534\n",
      "\n",
      "Epoch : 410\n",
      " Time:15.0\n",
      "Generator Loss: 3.7711944580078125 Discriminator Loss: 0.13991910219192505\n",
      "\n",
      "Epoch : 411\n",
      " Time:14.0\n",
      "Generator Loss: 2.7171661853790283 Discriminator Loss: 0.11929125338792801\n",
      "\n",
      "Epoch : 412\n",
      " Time:15.0\n",
      "Generator Loss: 3.7428345680236816 Discriminator Loss: 0.06793153285980225\n",
      "\n",
      "Epoch : 413\n",
      " Time:14.0\n",
      "Generator Loss: 5.278875350952148 Discriminator Loss: 0.03432726860046387\n",
      "\n",
      "Epoch : 414\n",
      " Time:14.0\n",
      "Generator Loss: 2.940068483352661 Discriminator Loss: 0.11852490156888962\n",
      "\n",
      "Epoch : 415\n",
      " Time:15.0\n",
      "Generator Loss: 5.479175090789795 Discriminator Loss: 0.2642435133457184\n",
      "\n",
      "Epoch : 416\n",
      " Time:14.0\n",
      "Generator Loss: 0.8967795372009277 Discriminator Loss: 0.7609376311302185\n",
      "\n",
      "Epoch : 417\n",
      " Time:15.0\n",
      "Generator Loss: 9.219380378723145 Discriminator Loss: 1.2865347862243652\n",
      "\n",
      "Epoch : 418\n",
      " Time:15.0\n",
      "Generator Loss: 2.421421527862549 Discriminator Loss: 0.1317458301782608\n",
      "\n",
      "Epoch : 419\n",
      " Time:15.0\n",
      "Generator Loss: 2.979909896850586 Discriminator Loss: 0.09010966122150421\n",
      "\n",
      "Epoch : 420\n",
      " Time:14.0\n",
      "Generator Loss: 4.52906608581543 Discriminator Loss: 0.07057720422744751\n",
      "\n",
      "Epoch : 421\n",
      " Time:15.0\n",
      "Generator Loss: 3.7824032306671143 Discriminator Loss: 0.029319308698177338\n",
      "\n",
      "Epoch : 422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Time:14.0\n",
      "Generator Loss: 4.161925315856934 Discriminator Loss: 0.030439812690019608\n",
      "\n",
      "Epoch : 423\n",
      " Time:15.0\n",
      "Generator Loss: 4.986638069152832 Discriminator Loss: 0.02301607094705105\n",
      "\n",
      "Epoch : 424\n",
      " Time:14.0\n",
      "Generator Loss: 7.593701362609863 Discriminator Loss: 0.007651984691619873\n",
      "\n",
      "Epoch : 425\n",
      " Time:15.0\n",
      "Generator Loss: 5.760194301605225 Discriminator Loss: 0.008236772380769253\n",
      "\n",
      "Epoch : 426\n",
      " Time:14.0\n",
      "Generator Loss: 3.612751007080078 Discriminator Loss: 0.06166337803006172\n",
      "\n",
      "Epoch : 427\n",
      " Time:15.0\n",
      "Generator Loss: 5.401562690734863 Discriminator Loss: 0.1562347561120987\n",
      "\n",
      "Epoch : 428\n",
      " Time:14.0\n",
      "Generator Loss: 0.211927130818367 Discriminator Loss: 2.5218565464019775\n",
      "\n",
      "Epoch : 429\n",
      " Time:14.0\n",
      "Generator Loss: 19.012773513793945 Discriminator Loss: 3.6145763397216797\n",
      "\n",
      "Epoch : 430\n",
      " Time:15.0\n",
      "Generator Loss: 5.585857391357422 Discriminator Loss: 0.2471398562192917\n",
      "\n",
      "Epoch : 431\n",
      " Time:14.0\n",
      "Generator Loss: 2.2084178924560547 Discriminator Loss: 0.16031284630298615\n",
      "\n",
      "Epoch : 432\n",
      " Time:15.0\n",
      "Generator Loss: 1.3858649730682373 Discriminator Loss: 0.3999968469142914\n",
      "\n",
      "Epoch : 433\n",
      " Time:14.0\n",
      "Generator Loss: 3.050466299057007 Discriminator Loss: 0.22577674686908722\n",
      "\n",
      "Epoch : 434\n",
      " Time:14.0\n",
      "Generator Loss: 1.7120345830917358 Discriminator Loss: 0.29087039828300476\n",
      "\n",
      "Epoch : 435\n",
      " Time:14.0\n",
      "Generator Loss: 3.833040237426758 Discriminator Loss: 0.22185567021369934\n",
      "\n",
      "Epoch : 436\n",
      " Time:14.0\n",
      "Generator Loss: 1.786319613456726 Discriminator Loss: 0.2918858230113983\n",
      "\n",
      "Epoch : 437\n",
      " Time:14.0\n",
      "Generator Loss: 4.659862518310547 Discriminator Loss: 0.339639812707901\n",
      "\n",
      "Epoch : 438\n",
      " Time:15.0\n",
      "Generator Loss: 1.2725934982299805 Discriminator Loss: 0.4709465801715851\n",
      "\n",
      "Epoch : 439\n",
      " Time:15.0\n",
      "Generator Loss: 6.769512176513672 Discriminator Loss: 0.840121328830719\n",
      "\n",
      "Epoch : 440\n",
      " Time:15.0\n",
      "Generator Loss: 3.153897285461426 Discriminator Loss: 0.07042253762483597\n",
      "\n",
      "Epoch : 441\n",
      " Time:14.0\n",
      "Generator Loss: 4.7921142578125 Discriminator Loss: 0.043157950043678284\n",
      "\n",
      "Epoch : 442\n",
      " Time:15.0\n",
      "Generator Loss: 3.2298474311828613 Discriminator Loss: 0.05574404075741768\n",
      "\n",
      "Epoch : 443\n",
      " Time:14.0\n",
      "Generator Loss: 3.9185404777526855 Discriminator Loss: 0.04621858522295952\n",
      "\n",
      "Epoch : 444\n",
      " Time:15.0\n",
      "Generator Loss: 5.67369270324707 Discriminator Loss: 0.01836453750729561\n",
      "\n",
      "Epoch : 445\n",
      " Time:15.0\n",
      "Generator Loss: 5.171999931335449 Discriminator Loss: 0.013373900204896927\n",
      "\n",
      "Epoch : 446\n",
      " Time:14.0\n",
      "Generator Loss: 3.208798885345459 Discriminator Loss: 0.050064049661159515\n",
      "\n",
      "Epoch : 447\n",
      " Time:14.0\n",
      "Generator Loss: 3.229224920272827 Discriminator Loss: 0.06973693519830704\n",
      "\n",
      "Epoch : 448\n",
      " Time:15.0\n",
      "Generator Loss: 4.941802978515625 Discriminator Loss: 0.06856218725442886\n",
      "\n",
      "Epoch : 449\n",
      " Time:15.0\n",
      "Generator Loss: 2.6720376014709473 Discriminator Loss: 0.08852174133062363\n",
      "\n",
      "Epoch : 450\n",
      " Time:14.0\n",
      "Generator Loss: 5.99416446685791 Discriminator Loss: 0.21043609082698822\n",
      "\n",
      "Epoch : 451\n",
      " Time:14.0\n",
      "Generator Loss: 0.4908295273780823 Discriminator Loss: 1.0539835691452026\n",
      "\n",
      "Epoch : 452\n",
      " Time:15.0\n",
      "Generator Loss: 14.050956726074219 Discriminator Loss: 2.4374396800994873\n",
      "\n",
      "Epoch : 453\n",
      " Time:15.0\n",
      "Generator Loss: 6.946187973022461 Discriminator Loss: 0.6515597701072693\n",
      "\n",
      "Epoch : 454\n",
      " Time:15.0\n",
      "Generator Loss: 1.6759767532348633 Discriminator Loss: 0.27118250727653503\n",
      "\n",
      "Epoch : 455\n",
      " Time:15.0\n",
      "Generator Loss: 6.254310607910156 Discriminator Loss: 0.4787747859954834\n",
      "\n",
      "Epoch : 456\n",
      " Time:15.0\n",
      "Generator Loss: 1.6139711141586304 Discriminator Loss: 0.3043406903743744\n",
      "\n",
      "Epoch : 457\n",
      " Time:15.0\n",
      "Generator Loss: 3.356416940689087 Discriminator Loss: 0.592929482460022\n",
      "\n",
      "Epoch : 458\n",
      " Time:15.0\n",
      "Generator Loss: 1.0094342231750488 Discriminator Loss: 0.4951103627681732\n",
      "\n",
      "Epoch : 459\n",
      " Time:15.0\n",
      "Generator Loss: 16.640525817871094 Discriminator Loss: 2.9839136600494385\n",
      "\n",
      "Epoch : 460\n",
      " Time:15.0\n",
      "Generator Loss: 5.819620132446289 Discriminator Loss: 0.0760837271809578\n",
      "\n",
      "Epoch : 461\n",
      " Time:15.0\n",
      "Generator Loss: 1.8881304264068604 Discriminator Loss: 0.1857612431049347\n",
      "\n",
      "Epoch : 462\n",
      " Time:14.0\n",
      "Generator Loss: 3.0170483589172363 Discriminator Loss: 0.11792914569377899\n",
      "\n",
      "Epoch : 463\n",
      " Time:14.0\n",
      "Generator Loss: 3.2043421268463135 Discriminator Loss: 0.06570109724998474\n",
      "\n",
      "Epoch : 464\n",
      " Time:15.0\n",
      "Generator Loss: 2.045261859893799 Discriminator Loss: 0.16828009486198425\n",
      "\n",
      "Epoch : 465\n",
      " Time:14.0\n",
      "Generator Loss: 4.679314613342285 Discriminator Loss: 0.3513263165950775\n",
      "\n",
      "Epoch : 466\n",
      " Time:15.0\n",
      "Generator Loss: 1.3121323585510254 Discriminator Loss: 0.36956122517585754\n",
      "\n",
      "Epoch : 467\n",
      " Time:14.0\n",
      "Generator Loss: 5.019627094268799 Discriminator Loss: 0.8116722106933594\n",
      "\n",
      "Epoch : 468\n",
      " Time:15.0\n",
      "Generator Loss: 1.4172964096069336 Discriminator Loss: 0.30927279591560364\n",
      "\n",
      "Epoch : 469\n",
      " Time:15.0\n",
      "Generator Loss: 7.554762840270996 Discriminator Loss: 0.8850847482681274\n",
      "\n",
      "Epoch : 470\n",
      " Time:15.0\n",
      "Generator Loss: 2.896070957183838 Discriminator Loss: 0.09531278908252716\n",
      "\n",
      "Epoch : 471\n",
      " Time:15.0\n",
      "Generator Loss: 3.8994648456573486 Discriminator Loss: 0.09769483655691147\n",
      "\n",
      "Epoch : 472\n",
      " Time:14.0\n",
      "Generator Loss: 2.063369035720825 Discriminator Loss: 0.1485351175069809\n",
      "\n",
      "Epoch : 473\n",
      " Time:15.0\n",
      "Generator Loss: 6.119256496429443 Discriminator Loss: 0.45075422525405884\n",
      "\n",
      "Epoch : 474\n",
      " Time:15.0\n",
      "Generator Loss: 1.1553211212158203 Discriminator Loss: 0.39170676469802856\n",
      "\n",
      "Epoch : 475\n",
      " Time:15.0\n",
      "Generator Loss: 4.876110076904297 Discriminator Loss: 0.9532136917114258\n",
      "\n",
      "Epoch : 476\n",
      " Time:15.0\n",
      "Generator Loss: 3.5318145751953125 Discriminator Loss: 0.044991619884967804\n",
      "\n",
      "Epoch : 477\n",
      " Time:15.0\n",
      "Generator Loss: 1.393261194229126 Discriminator Loss: 0.3222612142562866\n",
      "\n",
      "Epoch : 478\n",
      " Time:14.0\n",
      "Generator Loss: 12.895195007324219 Discriminator Loss: 1.6135830879211426\n",
      "\n",
      "Epoch : 479\n",
      " Time:15.0\n",
      "Generator Loss: 3.325213670730591 Discriminator Loss: 0.13397657871246338\n",
      "\n",
      "Epoch : 480\n",
      " Time:15.0\n",
      "Generator Loss: 1.8232319355010986 Discriminator Loss: 0.2082798182964325\n",
      "\n",
      "Epoch : 481\n",
      " Time:14.0\n",
      "Generator Loss: 5.166012287139893 Discriminator Loss: 0.57744300365448\n",
      "\n",
      "Epoch : 482\n",
      " Time:14.0\n",
      "Generator Loss: 2.652211904525757 Discriminator Loss: 0.08501432090997696\n",
      "\n",
      "Epoch : 483\n",
      " Time:14.0\n",
      "Generator Loss: 1.211733102798462 Discriminator Loss: 0.44706204533576965\n",
      "\n",
      "Epoch : 484\n",
      " Time:14.0\n",
      "Generator Loss: 9.832573890686035 Discriminator Loss: 1.1092510223388672\n",
      "\n",
      "Epoch : 485\n",
      " Time:15.0\n",
      "Generator Loss: 6.256582260131836 Discriminator Loss: 0.016267651692032814\n",
      "\n",
      "Epoch : 486\n",
      " Time:14.0\n",
      "Generator Loss: 2.8335680961608887 Discriminator Loss: 0.0700940415263176\n",
      "\n",
      "Epoch : 487\n",
      " Time:15.0\n",
      "Generator Loss: 2.2645702362060547 Discriminator Loss: 0.14137552678585052\n",
      "\n",
      "Epoch : 488\n",
      " Time:14.0\n",
      "Generator Loss: 4.426628112792969 Discriminator Loss: 0.2890802025794983\n",
      "\n",
      "Epoch : 489\n",
      " Time:14.0\n",
      "Generator Loss: 1.5441138744354248 Discriminator Loss: 0.27882111072540283\n",
      "\n",
      "Epoch : 490\n",
      " Time:15.0\n",
      "Generator Loss: 8.922798156738281 Discriminator Loss: 0.852868914604187\n",
      "\n",
      "Epoch : 491\n",
      " Time:15.0\n",
      "Generator Loss: 5.982542514801025 Discriminator Loss: 0.004562279675155878\n",
      "\n",
      "Epoch : 492\n",
      " Time:15.0\n",
      "Generator Loss: 2.1468286514282227 Discriminator Loss: 0.15294042229652405\n",
      "\n",
      "Epoch : 493\n",
      " Time:15.0\n",
      "Generator Loss: 5.977163314819336 Discriminator Loss: 0.4100590646266937\n",
      "\n",
      "Epoch : 494\n",
      " Time:14.0\n",
      "Generator Loss: 0.9354783296585083 Discriminator Loss: 0.6285842657089233\n",
      "\n",
      "Epoch : 495\n",
      " Time:14.0\n",
      "Generator Loss: 9.29145336151123 Discriminator Loss: 1.538419485092163\n",
      "\n",
      "Epoch : 496\n",
      " Time:15.0\n",
      "Generator Loss: 4.927517890930176 Discriminator Loss: 0.11457689106464386\n",
      "\n",
      "Epoch : 497\n",
      " Time:15.0\n",
      "Generator Loss: 1.5045465230941772 Discriminator Loss: 0.2982849180698395\n",
      "\n",
      "Epoch : 498\n",
      " Time:15.0\n",
      "Generator Loss: 7.809168815612793 Discriminator Loss: 1.0182290077209473\n",
      "\n",
      "Epoch : 499\n",
      " Time:14.0\n",
      "Generator Loss: 0.3933520019054413 Discriminator Loss: 1.1544207334518433\n",
      "\n",
      "Epoch : 500\n",
      " Time:14.0\n",
      "Generator Loss: 11.752538681030273 Discriminator Loss: 2.01395583152771\n",
      "\n",
      "Epoch : 501\n",
      " Time:15.0\n",
      "Generator Loss: 7.9910430908203125 Discriminator Loss: 0.9571052193641663\n",
      "\n",
      "Epoch : 502\n",
      " Time:14.0\n",
      "Generator Loss: 4.29280424118042 Discriminator Loss: 0.31854838132858276\n",
      "\n",
      "Epoch : 503\n",
      " Time:15.0\n",
      "Generator Loss: 1.894430160522461 Discriminator Loss: 0.20179596543312073\n",
      "\n",
      "Epoch : 504\n",
      " Time:14.0\n",
      "Generator Loss: 3.8241231441497803 Discriminator Loss: 0.3138906955718994\n",
      "\n",
      "Epoch : 505\n",
      " Time:14.0\n",
      "Generator Loss: 0.6918184757232666 Discriminator Loss: 0.7160971164703369\n",
      "\n",
      "Epoch : 506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Time:15.0\n",
      "Generator Loss: 7.532594680786133 Discriminator Loss: 1.2621021270751953\n",
      "\n",
      "Epoch : 507\n",
      " Time:14.0\n",
      "Generator Loss: 3.9305927753448486 Discriminator Loss: 0.43329307436943054\n",
      "\n",
      "Epoch : 508\n",
      " Time:15.0\n",
      "Generator Loss: 3.336556911468506 Discriminator Loss: 0.10353494435548782\n",
      "\n",
      "Epoch : 509\n",
      " Time:15.0\n",
      "Generator Loss: 3.2554359436035156 Discriminator Loss: 0.08052194863557816\n",
      "\n",
      "Epoch : 510\n",
      " Time:15.0\n",
      "Generator Loss: 3.8609228134155273 Discriminator Loss: 0.0659908652305603\n",
      "\n",
      "Epoch : 511\n",
      " Time:14.0\n",
      "Generator Loss: 2.6169023513793945 Discriminator Loss: 0.10318431258201599\n",
      "\n",
      "Epoch : 512\n",
      " Time:14.0\n",
      "Generator Loss: 5.124759197235107 Discriminator Loss: 0.11595044285058975\n",
      "\n",
      "Epoch : 513\n",
      " Time:15.0\n",
      "Generator Loss: 2.206782102584839 Discriminator Loss: 0.1403680443763733\n",
      "\n",
      "Epoch : 514\n",
      " Time:15.0\n",
      "Generator Loss: 3.2613327503204346 Discriminator Loss: 0.28603750467300415\n",
      "\n",
      "Epoch : 515\n",
      " Time:14.0\n",
      "Generator Loss: 0.8223568201065063 Discriminator Loss: 0.6198354363441467\n",
      "\n",
      "Epoch : 516\n",
      " Time:14.0\n",
      "Generator Loss: 23.421735763549805 Discriminator Loss: 3.9128477573394775\n",
      "\n",
      "Epoch : 517\n",
      " Time:15.0\n",
      "Generator Loss: 7.079796314239502 Discriminator Loss: 0.5535033345222473\n",
      "\n",
      "Epoch : 518\n",
      " Time:15.0\n",
      "Generator Loss: 4.64156436920166 Discriminator Loss: 0.04981324076652527\n",
      "\n",
      "Epoch : 519\n",
      " Time:14.0\n",
      "Generator Loss: 3.1868033409118652 Discriminator Loss: 0.05791246145963669\n",
      "\n",
      "Epoch : 520\n",
      " Time:14.0\n",
      "Generator Loss: 2.012465476989746 Discriminator Loss: 0.17693325877189636\n",
      "\n",
      "Epoch : 521\n",
      " Time:14.0\n",
      "Generator Loss: 3.0746078491210938 Discriminator Loss: 0.21359065175056458\n",
      "\n",
      "Epoch : 522\n",
      " Time:15.0\n",
      "Generator Loss: 1.548985481262207 Discriminator Loss: 0.279674768447876\n",
      "\n",
      "Epoch : 523\n",
      " Time:14.0\n",
      "Generator Loss: 5.838821887969971 Discriminator Loss: 0.7071090936660767\n",
      "\n",
      "Epoch : 524\n",
      " Time:14.0\n",
      "Generator Loss: 2.2486753463745117 Discriminator Loss: 0.13149257004261017\n",
      "\n",
      "Epoch : 525\n",
      " Time:15.0\n",
      "Generator Loss: 2.7280707359313965 Discriminator Loss: 0.17247866094112396\n",
      "\n",
      "Epoch : 526\n",
      " Time:14.0\n",
      "Generator Loss: 3.4513983726501465 Discriminator Loss: 0.07186038792133331\n",
      "\n",
      "Epoch : 527\n",
      " Time:14.0\n",
      "Generator Loss: 4.393868446350098 Discriminator Loss: 0.03437777981162071\n",
      "\n",
      "Epoch : 528\n",
      " Time:14.0\n",
      "Generator Loss: 3.3211216926574707 Discriminator Loss: 0.05184450373053551\n",
      "\n",
      "Epoch : 529\n",
      " Time:14.0\n",
      "Generator Loss: 2.853900194168091 Discriminator Loss: 0.09502439945936203\n",
      "\n",
      "Epoch : 530\n",
      " Time:14.0\n",
      "Generator Loss: 4.530018329620361 Discriminator Loss: 0.125218465924263\n",
      "\n",
      "Epoch : 531\n",
      " Time:14.0\n",
      "Generator Loss: 1.3353545665740967 Discriminator Loss: 0.33698514103889465\n",
      "\n",
      "Epoch : 532\n",
      " Time:15.0\n",
      "Generator Loss: 7.761324882507324 Discriminator Loss: 1.4563405513763428\n",
      "\n",
      "Epoch : 533\n",
      " Time:14.0\n",
      "Generator Loss: 2.412652015686035 Discriminator Loss: 0.18026785552501678\n",
      "\n",
      "Epoch : 534\n",
      " Time:15.0\n",
      "Generator Loss: 3.060335159301758 Discriminator Loss: 0.18512384593486786\n",
      "\n",
      "Epoch : 535\n",
      " Time:14.0\n",
      "Generator Loss: 2.405242681503296 Discriminator Loss: 0.1319732964038849\n",
      "\n",
      "Epoch : 536\n",
      " Time:14.0\n",
      "Generator Loss: 7.223093032836914 Discriminator Loss: 0.4241340458393097\n",
      "\n",
      "Epoch : 537\n",
      " Time:15.0\n",
      "Generator Loss: 1.4997297525405884 Discriminator Loss: 0.26636388897895813\n",
      "\n",
      "Epoch : 538\n",
      " Time:15.0\n",
      "Generator Loss: 4.110678672790527 Discriminator Loss: 0.8733984231948853\n",
      "\n",
      "Epoch : 539\n",
      " Time:15.0\n",
      "Generator Loss: 1.6899657249450684 Discriminator Loss: 0.21794411540031433\n",
      "\n",
      "Epoch : 540\n",
      " Time:14.0\n",
      "Generator Loss: 5.538226127624512 Discriminator Loss: 0.9983333945274353\n",
      "\n",
      "Epoch : 541\n",
      " Time:15.0\n",
      "Generator Loss: 7.946357727050781 Discriminator Loss: 0.005051859654486179\n",
      "\n",
      "Epoch : 542\n",
      " Time:14.0\n",
      "Generator Loss: 1.4890587329864502 Discriminator Loss: 0.2969790995121002\n",
      "\n",
      "Epoch : 543\n",
      " Time:15.0\n",
      "Generator Loss: 6.932187080383301 Discriminator Loss: 0.6088752746582031\n",
      "\n",
      "Epoch : 544\n",
      " Time:14.0\n",
      "Generator Loss: 3.2054495811462402 Discriminator Loss: 0.07094753533601761\n",
      "\n",
      "Epoch : 545\n",
      " Time:15.0\n",
      "Generator Loss: 2.1808300018310547 Discriminator Loss: 0.18349094688892365\n",
      "\n",
      "Epoch : 546\n",
      " Time:14.0\n",
      "Generator Loss: 3.9041194915771484 Discriminator Loss: 0.17142125964164734\n",
      "\n",
      "Epoch : 547\n",
      " Time:14.0\n",
      "Generator Loss: 4.769248008728027 Discriminator Loss: 0.012788508087396622\n",
      "\n",
      "Epoch : 548\n",
      " Time:14.0\n",
      "Generator Loss: 1.9059216976165771 Discriminator Loss: 0.17004160583019257\n",
      "\n",
      "Epoch : 549\n",
      " Time:14.0\n",
      "Generator Loss: 8.678616523742676 Discriminator Loss: 1.0448791980743408\n",
      "\n",
      "Epoch : 550\n",
      " Time:14.0\n",
      "Generator Loss: 0.6779541969299316 Discriminator Loss: 0.7265595197677612\n",
      "\n",
      "Epoch : 551\n",
      " Time:15.0\n",
      "Generator Loss: 9.940532684326172 Discriminator Loss: 1.8746029138565063\n",
      "\n",
      "Epoch : 552\n",
      " Time:14.0\n",
      "Generator Loss: 6.164089202880859 Discriminator Loss: 0.6350129842758179\n",
      "\n",
      "Epoch : 553\n",
      " Time:14.0\n",
      "Generator Loss: 1.545543909072876 Discriminator Loss: 0.28820961713790894\n",
      "\n",
      "Epoch : 554\n",
      " Time:14.0\n",
      "Generator Loss: 6.654181003570557 Discriminator Loss: 0.6981431245803833\n",
      "\n",
      "Epoch : 555\n",
      " Time:15.0\n",
      "Generator Loss: 3.5728578567504883 Discriminator Loss: 0.054883942008018494\n",
      "\n",
      "Epoch : 556\n",
      " Time:15.0\n",
      "Generator Loss: 2.985135078430176 Discriminator Loss: 0.08234921097755432\n",
      "\n",
      "Epoch : 557\n",
      " Time:15.0\n",
      "Generator Loss: 1.4028500318527222 Discriminator Loss: 0.3105011284351349\n",
      "\n",
      "Epoch : 558\n",
      " Time:14.0\n",
      "Generator Loss: 8.086305618286133 Discriminator Loss: 1.0795599222183228\n",
      "\n",
      "Epoch : 559\n",
      " Time:15.0\n",
      "Generator Loss: 3.132908344268799 Discriminator Loss: 0.08944256603717804\n",
      "\n",
      "Epoch : 560\n",
      " Time:15.0\n",
      "Generator Loss: 2.6281192302703857 Discriminator Loss: 0.12595012784004211\n",
      "\n",
      "Epoch : 561\n",
      " Time:15.0\n",
      "Generator Loss: 2.932809829711914 Discriminator Loss: 0.17789685726165771\n",
      "\n",
      "Epoch : 562\n",
      " Time:14.0\n",
      "Generator Loss: 3.8873727321624756 Discriminator Loss: 0.05721504986286163\n",
      "\n",
      "Epoch : 563\n",
      " Time:15.0\n",
      "Generator Loss: 0.9685506820678711 Discriminator Loss: 0.4972309470176697\n",
      "\n",
      "Epoch : 564\n",
      " Time:15.0\n",
      "Generator Loss: 14.180683135986328 Discriminator Loss: 2.1649904251098633\n",
      "\n",
      "Epoch : 565\n",
      " Time:14.0\n",
      "Generator Loss: 4.701152801513672 Discriminator Loss: 0.5109923481941223\n",
      "\n",
      "Epoch : 566\n",
      " Time:14.0\n",
      "Generator Loss: 2.8040637969970703 Discriminator Loss: 0.1001751646399498\n",
      "\n",
      "Epoch : 567\n",
      " Time:14.0\n",
      "Generator Loss: 3.892214775085449 Discriminator Loss: 0.14495186507701874\n",
      "\n",
      "Epoch : 568\n",
      " Time:14.0\n",
      "Generator Loss: 2.682839870452881 Discriminator Loss: 0.08454276621341705\n",
      "\n",
      "Epoch : 569\n",
      " Time:14.0\n",
      "Generator Loss: 1.786263346672058 Discriminator Loss: 0.21746204793453217\n",
      "\n",
      "Epoch : 570\n",
      " Time:14.0\n",
      "Generator Loss: 6.250920295715332 Discriminator Loss: 0.6628881692886353\n",
      "\n",
      "Epoch : 571\n",
      " Time:15.0\n",
      "Generator Loss: 6.057160377502441 Discriminator Loss: 0.010220685973763466\n",
      "\n",
      "Epoch : 572\n",
      " Time:14.0\n",
      "Generator Loss: 2.000023603439331 Discriminator Loss: 0.16949462890625\n",
      "\n",
      "Epoch : 573\n",
      " Time:14.0\n",
      "Generator Loss: 3.2051661014556885 Discriminator Loss: 0.2990233898162842\n",
      "\n",
      "Epoch : 574\n",
      " Time:14.0\n",
      "Generator Loss: 1.3158464431762695 Discriminator Loss: 0.34006497263908386\n",
      "\n",
      "Epoch : 575\n",
      " Time:14.0\n",
      "Generator Loss: 5.698923110961914 Discriminator Loss: 1.2597965002059937\n",
      "\n",
      "Epoch : 576\n",
      " Time:15.0\n",
      "Generator Loss: 2.4182817935943604 Discriminator Loss: 0.17460080981254578\n",
      "\n",
      "Epoch : 577\n",
      " Time:15.0\n",
      "Generator Loss: 5.2431159019470215 Discriminator Loss: 0.15825405716896057\n",
      "\n",
      "Epoch : 578\n",
      " Time:14.0\n",
      "Generator Loss: 1.529853343963623 Discriminator Loss: 0.27577221393585205\n",
      "\n",
      "Epoch : 579\n",
      " Time:15.0\n",
      "Generator Loss: 6.07813835144043 Discriminator Loss: 0.7252377271652222\n",
      "\n",
      "Epoch : 580\n",
      " Time:15.0\n",
      "Generator Loss: 1.9411541223526 Discriminator Loss: 0.17475785315036774\n",
      "\n",
      "Epoch : 581\n",
      " Time:14.0\n",
      "Generator Loss: 2.467803955078125 Discriminator Loss: 0.5045279860496521\n",
      "\n",
      "Epoch : 582\n",
      " Time:15.0\n",
      "Generator Loss: 1.488871693611145 Discriminator Loss: 0.309566855430603\n",
      "\n",
      "Epoch : 583\n",
      " Time:15.0\n",
      "Generator Loss: 9.476694107055664 Discriminator Loss: 1.412172794342041\n",
      "\n",
      "Epoch : 584\n",
      " Time:15.0\n",
      "Generator Loss: 6.589932441711426 Discriminator Loss: 0.045041803270578384\n",
      "\n",
      "Epoch : 585\n",
      " Time:14.0\n",
      "Generator Loss: 2.9440417289733887 Discriminator Loss: 0.06825859099626541\n",
      "\n",
      "Epoch : 586\n",
      " Time:15.0\n",
      "Generator Loss: 2.006422996520996 Discriminator Loss: 0.1767645627260208\n",
      "\n",
      "Epoch : 587\n",
      " Time:14.0\n",
      "Generator Loss: 5.076236724853516 Discriminator Loss: 0.4050253927707672\n",
      "\n",
      "Epoch : 588\n",
      " Time:14.0\n",
      "Generator Loss: 3.378478527069092 Discriminator Loss: 0.050128113478422165\n",
      "\n",
      "Epoch : 589\n",
      " Time:15.0\n",
      "Generator Loss: 3.255779266357422 Discriminator Loss: 0.05946767330169678\n",
      "\n",
      "Epoch : 590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Time:15.0\n",
      "Generator Loss: 2.055341958999634 Discriminator Loss: 0.1796940267086029\n",
      "\n",
      "Epoch : 591\n",
      " Time:15.0\n",
      "Generator Loss: 6.484100341796875 Discriminator Loss: 0.5279023051261902\n",
      "\n",
      "Epoch : 592\n",
      " Time:14.0\n",
      "Generator Loss: 2.258042812347412 Discriminator Loss: 0.17075780034065247\n",
      "\n",
      "Epoch : 593\n",
      " Time:15.0\n",
      "Generator Loss: 3.7052838802337646 Discriminator Loss: 0.3887999355792999\n",
      "\n",
      "Epoch : 594\n",
      " Time:15.0\n",
      "Generator Loss: 0.7739817500114441 Discriminator Loss: 0.6589668989181519\n",
      "\n",
      "Epoch : 595\n",
      " Time:15.0\n",
      "Generator Loss: 18.364362716674805 Discriminator Loss: 2.9504330158233643\n",
      "\n",
      "Epoch : 596\n",
      " Time:14.0\n",
      "Generator Loss: 7.803445816040039 Discriminator Loss: 0.6900915503501892\n",
      "\n",
      "Epoch : 597\n",
      " Time:15.0\n",
      "Generator Loss: 4.587157249450684 Discriminator Loss: 0.07431767880916595\n",
      "\n",
      "Epoch : 598\n",
      " Time:15.0\n",
      "Generator Loss: 1.6890537738800049 Discriminator Loss: 0.22820019721984863\n",
      "\n",
      "Epoch : 599\n",
      " Time:14.0\n",
      "Generator Loss: 3.624763011932373 Discriminator Loss: 0.3153926730155945\n",
      "\n",
      "Epoch : 600\n",
      " Time:15.0\n",
      "Generator Loss: 1.7593594789505005 Discriminator Loss: 0.21533627808094025\n",
      "\n",
      "Epoch : 601\n",
      " Time:15.0\n",
      "Generator Loss: 3.7036292552948 Discriminator Loss: 0.4182169735431671\n",
      "\n",
      "Epoch : 602\n",
      " Time:15.0\n",
      "Generator Loss: 2.935654640197754 Discriminator Loss: 0.06793612986803055\n",
      "\n",
      "Epoch : 603\n",
      " Time:14.0\n",
      "Generator Loss: 3.5324792861938477 Discriminator Loss: 0.05608437955379486\n",
      "\n",
      "Epoch : 604\n",
      " Time:15.0\n",
      "Generator Loss: 2.392977237701416 Discriminator Loss: 0.12597768008708954\n",
      "\n",
      "Epoch : 605\n",
      " Time:15.0\n",
      "Generator Loss: 3.547434091567993 Discriminator Loss: 0.2445172816514969\n",
      "\n",
      "Epoch : 606\n",
      " Time:15.0\n",
      "Generator Loss: 3.1816482543945312 Discriminator Loss: 0.056082673370838165\n",
      "\n",
      "Epoch : 607\n",
      " Time:14.0\n",
      "Generator Loss: 2.6462626457214355 Discriminator Loss: 0.10479911416769028\n",
      "\n",
      "Epoch : 608\n",
      " Time:14.0\n",
      "Generator Loss: 8.075739860534668 Discriminator Loss: 0.1716310977935791\n",
      "\n",
      "Epoch : 609\n",
      " Time:14.0\n",
      "Generator Loss: 0.3045424818992615 Discriminator Loss: 1.3622252941131592\n",
      "\n",
      "Epoch : 610\n",
      " Time:15.0\n",
      "Generator Loss: 15.132412910461426 Discriminator Loss: 2.188555955886841\n",
      "\n",
      "Epoch : 611\n",
      " Time:15.0\n",
      "Generator Loss: 7.391168594360352 Discriminator Loss: 0.9070819616317749\n",
      "\n",
      "Epoch : 612\n",
      " Time:15.0\n",
      "Generator Loss: 4.15274715423584 Discriminator Loss: 0.3039918839931488\n",
      "\n",
      "Epoch : 613\n",
      " Time:15.0\n",
      "Generator Loss: 3.0328946113586426 Discriminator Loss: 0.10422861576080322\n",
      "\n",
      "Epoch : 614\n",
      " Time:15.0\n",
      "Generator Loss: 2.071768283843994 Discriminator Loss: 0.18857093155384064\n",
      "\n",
      "Epoch : 615\n",
      " Time:14.0\n",
      "Generator Loss: 3.626511812210083 Discriminator Loss: 0.19110752642154694\n",
      "\n",
      "Epoch : 616\n",
      " Time:15.0\n",
      "Generator Loss: 1.875361680984497 Discriminator Loss: 0.2162860482931137\n",
      "\n",
      "Epoch : 617\n",
      " Time:15.0\n",
      "Generator Loss: 4.372284412384033 Discriminator Loss: 0.2847205698490143\n",
      "\n",
      "Epoch : 618\n",
      " Time:15.0\n",
      "Generator Loss: 1.681755542755127 Discriminator Loss: 0.24172206223011017\n",
      "\n",
      "Epoch : 619\n",
      " Time:15.0\n",
      "Generator Loss: 5.184053897857666 Discriminator Loss: 0.4892067313194275\n",
      "\n",
      "Epoch : 620\n",
      " Time:14.0\n",
      "Generator Loss: 1.2330470085144043 Discriminator Loss: 0.3774835467338562\n",
      "\n",
      "Epoch : 621\n",
      " Time:15.0\n",
      "Generator Loss: 6.636224269866943 Discriminator Loss: 0.994594395160675\n",
      "\n",
      "Epoch : 622\n",
      " Time:15.0\n",
      "Generator Loss: 5.262674331665039 Discriminator Loss: 0.08379865437746048\n",
      "\n",
      "Epoch : 623\n",
      " Time:15.0\n",
      "Generator Loss: 4.3855743408203125 Discriminator Loss: 0.02554335445165634\n",
      "\n",
      "Epoch : 624\n",
      " Time:15.0\n",
      "Generator Loss: 2.1089558601379395 Discriminator Loss: 0.14318959414958954\n",
      "\n",
      "Epoch : 625\n",
      " Time:14.0\n",
      "Generator Loss: 3.9109818935394287 Discriminator Loss: 0.20293959975242615\n",
      "\n",
      "Epoch : 626\n",
      " Time:15.0\n",
      "Generator Loss: 0.7894665002822876 Discriminator Loss: 0.6286684274673462\n",
      "\n",
      "Epoch : 627\n",
      " Time:15.0\n",
      "Generator Loss: 7.896895885467529 Discriminator Loss: 1.4999603033065796\n",
      "\n",
      "Epoch : 628\n",
      " Time:15.0\n",
      "Generator Loss: 4.738443374633789 Discriminator Loss: 0.3849087357521057\n",
      "\n",
      "Epoch : 629\n",
      " Time:14.0\n",
      "Generator Loss: 2.092522621154785 Discriminator Loss: 0.16132909059524536\n",
      "\n",
      "Epoch : 630\n",
      " Time:14.0\n",
      "Generator Loss: 3.9513938426971436 Discriminator Loss: 0.21556207537651062\n",
      "\n",
      "Epoch : 631\n",
      " Time:14.0\n",
      "Generator Loss: 2.7468056678771973 Discriminator Loss: 0.08175244182348251\n",
      "\n",
      "Epoch : 632\n",
      " Time:15.0\n",
      "Generator Loss: 3.6190664768218994 Discriminator Loss: 0.0570121631026268\n",
      "\n",
      "Epoch : 633\n",
      " Time:15.0\n",
      "Generator Loss: 2.8111648559570312 Discriminator Loss: 0.08785973489284515\n",
      "\n",
      "Epoch : 634\n",
      " Time:14.0\n",
      "Generator Loss: 3.380580425262451 Discriminator Loss: 0.134381502866745\n",
      "\n",
      "Epoch : 635\n",
      " Time:14.0\n",
      "Generator Loss: 2.217042922973633 Discriminator Loss: 0.1538119614124298\n",
      "\n",
      "Epoch : 636\n",
      " Time:14.0\n",
      "Generator Loss: 4.602870941162109 Discriminator Loss: 0.3530566096305847\n",
      "\n",
      "Epoch : 637\n",
      " Time:15.0\n",
      "Generator Loss: 2.25775146484375 Discriminator Loss: 0.12754714488983154\n",
      "\n",
      "Epoch : 638\n",
      " Time:14.0\n",
      "Generator Loss: 1.343048334121704 Discriminator Loss: 0.5006239414215088\n",
      "\n",
      "Epoch : 639\n",
      " Time:15.0\n",
      "Generator Loss: 7.518411636352539 Discriminator Loss: 0.9135392904281616\n",
      "\n",
      "Epoch : 640\n",
      " Time:14.0\n",
      "Generator Loss: 7.296241283416748 Discriminator Loss: 0.012051451951265335\n",
      "\n",
      "Epoch : 641\n",
      " Time:14.0\n",
      "Generator Loss: 2.4527268409729004 Discriminator Loss: 0.10427172482013702\n",
      "\n",
      "Epoch : 642\n",
      " Time:14.0\n",
      "Generator Loss: 2.8711771965026855 Discriminator Loss: 0.11737892031669617\n",
      "\n",
      "Epoch : 643\n",
      " Time:14.0\n",
      "Generator Loss: 3.592010259628296 Discriminator Loss: 0.07448804378509521\n",
      "\n",
      "Epoch : 644\n",
      " Time:15.0\n",
      "Generator Loss: 3.9620401859283447 Discriminator Loss: 0.043107353150844574\n",
      "\n",
      "Epoch : 645\n",
      " Time:14.0\n",
      "Generator Loss: 6.231873035430908 Discriminator Loss: 0.022497249767184258\n",
      "\n",
      "Epoch : 646\n",
      " Time:14.0\n",
      "Generator Loss: 2.8884024620056152 Discriminator Loss: 0.06755796819925308\n",
      "\n",
      "Epoch : 647\n",
      " Time:15.0\n",
      "Generator Loss: 5.519911289215088 Discriminator Loss: 0.18193931877613068\n",
      "\n",
      "Epoch : 648\n",
      " Time:14.0\n",
      "Generator Loss: 0.24992108345031738 Discriminator Loss: 1.6055678129196167\n",
      "\n",
      "Epoch : 649\n",
      " Time:14.0\n",
      "Generator Loss: 12.460965156555176 Discriminator Loss: 1.985561728477478\n",
      "\n",
      "Epoch : 650\n",
      " Time:15.0\n",
      "Generator Loss: 7.3536200523376465 Discriminator Loss: 0.6850067973136902\n",
      "\n",
      "Epoch : 651\n",
      " Time:14.0\n",
      "Generator Loss: 4.460911750793457 Discriminator Loss: 0.23576390743255615\n",
      "\n",
      "Epoch : 652\n",
      " Time:15.0\n",
      "Generator Loss: 2.2587575912475586 Discriminator Loss: 0.16005289554595947\n",
      "\n",
      "Epoch : 653\n",
      " Time:14.0\n",
      "Generator Loss: 2.936300754547119 Discriminator Loss: 0.1771085560321808\n",
      "\n",
      "Epoch : 654\n",
      " Time:15.0\n",
      "Generator Loss: 1.3783066272735596 Discriminator Loss: 0.32971614599227905\n",
      "\n",
      "Epoch : 655\n",
      " Time:15.0\n",
      "Generator Loss: 8.005783081054688 Discriminator Loss: 0.966611921787262\n",
      "\n",
      "Epoch : 656\n",
      " Time:15.0\n",
      "Generator Loss: 2.601013660430908 Discriminator Loss: 0.16273942589759827\n",
      "\n",
      "Epoch : 657\n",
      " Time:15.0\n",
      "Generator Loss: 4.102487564086914 Discriminator Loss: 0.08721031993627548\n",
      "\n",
      "Epoch : 658\n",
      " Time:15.0\n",
      "Generator Loss: 2.7575669288635254 Discriminator Loss: 0.09669116139411926\n",
      "\n",
      "Epoch : 659\n",
      " Time:15.0\n",
      "Generator Loss: 3.9917359352111816 Discriminator Loss: 0.1601601541042328\n",
      "\n",
      "Epoch : 660\n",
      " Time:15.0\n",
      "Generator Loss: 1.7969632148742676 Discriminator Loss: 0.21997497975826263\n",
      "\n",
      "Epoch : 661\n",
      " Time:14.0\n",
      "Generator Loss: 4.130121231079102 Discriminator Loss: 0.6247970461845398\n",
      "\n",
      "Epoch : 662\n",
      " Time:15.0\n",
      "Generator Loss: 0.5982065200805664 Discriminator Loss: 0.8342738747596741\n",
      "\n",
      "Epoch : 663\n",
      " Time:15.0\n",
      "Generator Loss: 8.316070556640625 Discriminator Loss: 1.306473731994629\n",
      "\n",
      "Epoch : 664\n",
      " Time:15.0\n",
      "Generator Loss: 5.696577548980713 Discriminator Loss: 0.46551018953323364\n",
      "\n",
      "Epoch : 665\n",
      " Time:15.0\n",
      "Generator Loss: 2.238276481628418 Discriminator Loss: 0.19589465856552124\n",
      "\n",
      "Epoch : 666\n",
      " Time:15.0\n",
      "Generator Loss: 4.835999488830566 Discriminator Loss: 0.16707392036914825\n",
      "\n",
      "Epoch : 667\n",
      " Time:15.0\n",
      "Generator Loss: 2.715933322906494 Discriminator Loss: 0.10379092395305634\n",
      "\n",
      "Epoch : 668\n",
      " Time:15.0\n",
      "Generator Loss: 4.761213302612305 Discriminator Loss: 0.07317837327718735\n",
      "\n",
      "Epoch : 669\n",
      " Time:15.0\n",
      "Generator Loss: 2.5947928428649902 Discriminator Loss: 0.10948081314563751\n",
      "\n",
      "Epoch : 670\n",
      " Time:15.0\n",
      "Generator Loss: 5.158191204071045 Discriminator Loss: 0.1805947721004486\n",
      "\n",
      "Epoch : 671\n",
      " Time:14.0\n",
      "Generator Loss: 1.585699200630188 Discriminator Loss: 0.2968771159648895\n",
      "\n",
      "Epoch : 672\n",
      " Time:14.0\n",
      "Generator Loss: 4.065798759460449 Discriminator Loss: 0.5927319526672363\n",
      "\n",
      "Epoch : 673\n",
      " Time:14.0\n",
      "Generator Loss: 1.9572162628173828 Discriminator Loss: 0.20298555493354797\n",
      "\n",
      "Epoch : 674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Time:15.0\n",
      "Generator Loss: 7.637513160705566 Discriminator Loss: 0.6155706644058228\n",
      "\n",
      "Epoch : 675\n",
      " Time:14.0\n",
      "Generator Loss: 1.7259165048599243 Discriminator Loss: 0.2690353989601135\n",
      "\n",
      "Epoch : 676\n",
      " Time:14.0\n",
      "Generator Loss: 4.138175964355469 Discriminator Loss: 0.5519506931304932\n",
      "\n",
      "Epoch : 677\n",
      " Time:14.0\n",
      "Generator Loss: 2.983426332473755 Discriminator Loss: 0.07726172357797623\n",
      "\n",
      "Epoch : 678\n",
      " Time:14.0\n",
      "Generator Loss: 3.245330810546875 Discriminator Loss: 0.09613419324159622\n",
      "\n",
      "Epoch : 679\n",
      " Time:14.0\n",
      "Generator Loss: 3.9828169345855713 Discriminator Loss: 0.07440736889839172\n",
      "\n",
      "Epoch : 680\n",
      " Time:14.0\n",
      "Generator Loss: 5.322220325469971 Discriminator Loss: 0.020819509401917458\n",
      "\n",
      "Epoch : 681\n",
      " Time:14.0\n",
      "Generator Loss: 1.7842025756835938 Discriminator Loss: 0.20510812103748322\n",
      "\n",
      "Epoch : 682\n",
      " Time:14.0\n",
      "Generator Loss: 8.790953636169434 Discriminator Loss: 1.3148773908615112\n",
      "\n",
      "Epoch : 683\n",
      " Time:14.0\n",
      "Generator Loss: 1.8226327896118164 Discriminator Loss: 0.19695477187633514\n",
      "\n",
      "Epoch : 684\n",
      " Time:15.0\n",
      "Generator Loss: 4.2134270668029785 Discriminator Loss: 0.5305184721946716\n",
      "\n",
      "Epoch : 685\n",
      " Time:15.0\n",
      "Generator Loss: 3.2131786346435547 Discriminator Loss: 0.053842633962631226\n",
      "\n",
      "Epoch : 686\n",
      " Time:15.0\n",
      "Generator Loss: 1.703596830368042 Discriminator Loss: 0.22127245366573334\n",
      "\n",
      "Epoch : 687\n",
      " Time:15.0\n",
      "Generator Loss: 6.368391990661621 Discriminator Loss: 0.8409240245819092\n",
      "\n",
      "Epoch : 688\n",
      " Time:15.0\n",
      "Generator Loss: 4.944986343383789 Discriminator Loss: 0.02484384924173355\n",
      "\n",
      "Epoch : 689\n",
      " Time:15.0\n",
      "Generator Loss: 2.4938552379608154 Discriminator Loss: 0.10982445627450943\n",
      "\n",
      "Epoch : 690\n",
      " Time:14.0\n",
      "Generator Loss: 2.2438158988952637 Discriminator Loss: 0.23482927680015564\n",
      "\n",
      "Epoch : 691\n",
      " Time:15.0\n",
      "Generator Loss: 2.6922786235809326 Discriminator Loss: 0.2846107482910156\n",
      "\n",
      "Epoch : 692\n",
      " Time:14.0\n",
      "Generator Loss: 2.3122940063476562 Discriminator Loss: 0.15532022714614868\n",
      "\n",
      "Epoch : 693\n",
      " Time:15.0\n",
      "Generator Loss: 4.301374912261963 Discriminator Loss: 0.3542097210884094\n",
      "\n",
      "Epoch : 694\n",
      " Time:14.0\n",
      "Generator Loss: 1.5588023662567139 Discriminator Loss: 0.28241509199142456\n",
      "\n",
      "Epoch : 695\n",
      " Time:15.0\n",
      "Generator Loss: 3.7437381744384766 Discriminator Loss: 0.7656422853469849\n",
      "\n",
      "Epoch : 696\n",
      " Time:14.0\n",
      "Generator Loss: 2.7745354175567627 Discriminator Loss: 0.09592542052268982\n",
      "\n",
      "Epoch : 697\n",
      " Time:15.0\n",
      "Generator Loss: 6.293344020843506 Discriminator Loss: 0.14696000516414642\n",
      "\n",
      "Epoch : 698\n",
      " Time:14.0\n",
      "Generator Loss: 1.6547526121139526 Discriminator Loss: 0.22346262633800507\n",
      "\n",
      "Epoch : 699\n",
      " Time:14.0\n",
      "Generator Loss: 4.772089004516602 Discriminator Loss: 0.7253667116165161\n",
      "\n",
      "Epoch : 700\n",
      " Time:15.0\n",
      "Generator Loss: 2.264207601547241 Discriminator Loss: 0.14399440586566925\n",
      "\n",
      "Epoch : 701\n",
      " Time:14.0\n",
      "Generator Loss: 4.090412616729736 Discriminator Loss: 0.3579634130001068\n",
      "\n",
      "Epoch : 702\n",
      " Time:14.0\n",
      "Generator Loss: 3.4076266288757324 Discriminator Loss: 0.04607263579964638\n",
      "\n",
      "Epoch : 703\n",
      " Time:14.0\n",
      "Generator Loss: 4.780129432678223 Discriminator Loss: 0.02968588098883629\n",
      "\n",
      "Epoch : 704\n",
      " Time:15.0\n",
      "Generator Loss: 1.4189552068710327 Discriminator Loss: 0.29357075691223145\n",
      "\n",
      "Epoch : 705\n",
      " Time:14.0\n",
      "Generator Loss: 9.376422882080078 Discriminator Loss: 1.4596905708312988\n",
      "\n",
      "Epoch : 706\n",
      " Time:15.0\n",
      "Generator Loss: 2.744223117828369 Discriminator Loss: 0.17981094121932983\n",
      "\n",
      "Epoch : 707\n",
      " Time:15.0\n",
      "Generator Loss: 4.374074935913086 Discriminator Loss: 0.056076422333717346\n",
      "\n",
      "Epoch : 708\n",
      " Time:15.0\n",
      "Generator Loss: 2.1330337524414062 Discriminator Loss: 0.14406190812587738\n",
      "\n",
      "Epoch : 709\n",
      " Time:15.0\n",
      "Generator Loss: 5.572052001953125 Discriminator Loss: 0.38339948654174805\n",
      "\n",
      "Epoch : 710\n",
      " Time:15.0\n",
      "Generator Loss: 0.7887452840805054 Discriminator Loss: 0.684424638748169\n",
      "\n",
      "Epoch : 711\n",
      " Time:14.0\n",
      "Generator Loss: 6.831293106079102 Discriminator Loss: 1.4026515483856201\n",
      "\n",
      "Epoch : 712\n",
      " Time:15.0\n",
      "Generator Loss: 7.185842037200928 Discriminator Loss: 0.4750945270061493\n",
      "\n",
      "Epoch : 713\n",
      " Time:15.0\n",
      "Generator Loss: 2.0229201316833496 Discriminator Loss: 0.20873646438121796\n",
      "\n",
      "Epoch : 714\n",
      " Time:14.0\n",
      "Generator Loss: 3.848632335662842 Discriminator Loss: 0.4017094671726227\n",
      "\n",
      "Epoch : 715\n",
      " Time:14.0\n",
      "Generator Loss: 1.7936193943023682 Discriminator Loss: 0.21412864327430725\n",
      "\n",
      "Epoch : 716\n",
      " Time:15.0\n",
      "Generator Loss: 2.0588905811309814 Discriminator Loss: 0.526673436164856\n",
      "\n",
      "Epoch : 717\n",
      " Time:15.0\n",
      "Generator Loss: 2.9552178382873535 Discriminator Loss: 0.3096233606338501\n",
      "\n",
      "Epoch : 718\n",
      " Time:15.0\n",
      "Generator Loss: 2.636392116546631 Discriminator Loss: 0.09889872372150421\n",
      "\n",
      "Epoch : 719\n",
      " Time:15.0\n",
      "Generator Loss: 2.210242748260498 Discriminator Loss: 0.1985388547182083\n",
      "\n",
      "Epoch : 720\n",
      " Time:15.0\n",
      "Generator Loss: 3.666130781173706 Discriminator Loss: 0.39627113938331604\n",
      "\n",
      "Epoch : 721\n",
      " Time:15.0\n",
      "Generator Loss: 3.7872190475463867 Discriminator Loss: 0.04091605544090271\n",
      "\n",
      "Epoch : 722\n",
      " Time:14.0\n",
      "Generator Loss: 3.813126802444458 Discriminator Loss: 0.040812186896800995\n",
      "\n",
      "Epoch : 723\n",
      " Time:15.0\n",
      "Generator Loss: 1.4810479879379272 Discriminator Loss: 0.2833198606967926\n",
      "\n",
      "Epoch : 724\n",
      " Time:15.0\n",
      "Generator Loss: 8.538870811462402 Discriminator Loss: 1.064346432685852\n",
      "\n",
      "Epoch : 725\n",
      " Time:14.0\n",
      "Generator Loss: 1.7251802682876587 Discriminator Loss: 0.23926521837711334\n",
      "\n",
      "Epoch : 726\n",
      " Time:15.0\n",
      "Generator Loss: 5.68869686126709 Discriminator Loss: 0.6352092027664185\n",
      "\n",
      "Epoch : 727\n",
      " Time:15.0\n",
      "Generator Loss: 3.3124959468841553 Discriminator Loss: 0.06679663062095642\n",
      "\n",
      "Epoch : 728\n",
      " Time:15.0\n",
      "Generator Loss: 5.4770002365112305 Discriminator Loss: 0.0364227332174778\n",
      "\n",
      "Epoch : 729\n",
      " Time:14.0\n",
      "Generator Loss: 1.9207322597503662 Discriminator Loss: 0.18215563893318176\n",
      "\n",
      "Epoch : 730\n",
      " Time:15.0\n",
      "Generator Loss: 5.970524787902832 Discriminator Loss: 0.6498226523399353\n",
      "\n",
      "Epoch : 731\n",
      " Time:14.0\n",
      "Generator Loss: 1.4282007217407227 Discriminator Loss: 0.3446713089942932\n",
      "\n",
      "Epoch : 732\n",
      " Time:14.0\n",
      "Generator Loss: 6.040279865264893 Discriminator Loss: 0.9888623952865601\n",
      "\n",
      "Epoch : 733\n",
      " Time:14.0\n",
      "Generator Loss: 3.354203462600708 Discriminator Loss: 0.1264503002166748\n",
      "\n",
      "Epoch : 734\n",
      " Time:14.0\n",
      "Generator Loss: 2.2199277877807617 Discriminator Loss: 0.14796555042266846\n",
      "\n",
      "Epoch : 735\n",
      " Time:14.0\n",
      "Generator Loss: 3.84596586227417 Discriminator Loss: 0.47856026887893677\n",
      "\n",
      "Epoch : 736\n",
      " Time:15.0\n",
      "Generator Loss: 3.3144054412841797 Discriminator Loss: 0.060733549296855927\n",
      "\n",
      "Epoch : 737\n",
      " Time:15.0\n",
      "Generator Loss: 3.646468162536621 Discriminator Loss: 0.07819504290819168\n",
      "\n",
      "Epoch : 738\n",
      " Time:15.0\n",
      "Generator Loss: 0.8536100387573242 Discriminator Loss: 0.6210616230964661\n",
      "\n",
      "Epoch : 739\n",
      " Time:14.0\n",
      "Generator Loss: 13.122150421142578 Discriminator Loss: 1.802386999130249\n",
      "\n",
      "Epoch : 740\n",
      " Time:15.0\n",
      "Generator Loss: 8.968144416809082 Discriminator Loss: 0.4703707695007324\n",
      "\n",
      "Epoch : 741\n",
      " Time:14.0\n",
      "Generator Loss: 3.6748156547546387 Discriminator Loss: 0.06591079384088516\n",
      "\n",
      "Epoch : 742\n",
      " Time:14.0\n",
      "Generator Loss: 1.8274691104888916 Discriminator Loss: 0.20171043276786804\n",
      "\n",
      "Epoch : 743\n",
      " Time:15.0\n",
      "Generator Loss: 7.706830978393555 Discriminator Loss: 0.2634618282318115\n",
      "\n",
      "Epoch : 744\n",
      " Time:14.0\n",
      "Generator Loss: 2.2015998363494873 Discriminator Loss: 0.15101732313632965\n",
      "\n",
      "Epoch : 745\n",
      " Time:14.0\n",
      "Generator Loss: 3.9024291038513184 Discriminator Loss: 0.1834816038608551\n",
      "\n",
      "Epoch : 746\n",
      " Time:14.0\n",
      "Generator Loss: 1.4557898044586182 Discriminator Loss: 0.2951233983039856\n",
      "\n",
      "Epoch : 747\n",
      " Time:15.0\n",
      "Generator Loss: 5.714113235473633 Discriminator Loss: 0.7137908339500427\n",
      "\n",
      "Epoch : 748\n",
      " Time:14.0\n",
      "Generator Loss: 1.7581794261932373 Discriminator Loss: 0.21644867956638336\n",
      "\n",
      "Epoch : 749\n",
      " Time:14.0\n",
      "Generator Loss: 4.820051670074463 Discriminator Loss: 0.5409858822822571\n",
      "\n",
      "Epoch : 750\n",
      " Time:14.0\n",
      "Generator Loss: 4.733597278594971 Discriminator Loss: 0.026276294142007828\n",
      "\n",
      "Epoch : 751\n",
      " Time:15.0\n",
      "Generator Loss: 1.6813040971755981 Discriminator Loss: 0.23337829113006592\n",
      "\n",
      "Epoch : 752\n",
      " Time:14.0\n",
      "Generator Loss: 4.605404853820801 Discriminator Loss: 0.6458479166030884\n",
      "\n",
      "Epoch : 753\n",
      " Time:14.0\n",
      "Generator Loss: 3.433716297149658 Discriminator Loss: 0.04884907230734825\n",
      "\n",
      "Epoch : 754\n",
      " Time:14.0\n",
      "Generator Loss: 1.499359369277954 Discriminator Loss: 0.2814313471317291\n",
      "\n",
      "Epoch : 755\n",
      " Time:15.0\n",
      "Generator Loss: 4.746758460998535 Discriminator Loss: 0.8129419684410095\n",
      "\n",
      "Epoch : 756\n",
      " Time:15.0\n",
      "Generator Loss: 3.768683910369873 Discriminator Loss: 0.060671109706163406\n",
      "\n",
      "Epoch : 757\n",
      " Time:14.0\n",
      "Generator Loss: 4.833351135253906 Discriminator Loss: 0.035671114921569824\n",
      "\n",
      "Epoch : 758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Time:14.0\n",
      "Generator Loss: 1.5272698402404785 Discriminator Loss: 0.2647857367992401\n",
      "\n",
      "Epoch : 759\n",
      " Time:15.0\n",
      "Generator Loss: 5.641862869262695 Discriminator Loss: 0.9831468462944031\n",
      "\n",
      "Epoch : 760\n",
      " Time:15.0\n",
      "Generator Loss: 2.8835830688476562 Discriminator Loss: 0.09591703116893768\n",
      "\n",
      "Epoch : 761\n",
      " Time:14.0\n",
      "Generator Loss: 3.5337791442871094 Discriminator Loss: 0.09499466419219971\n",
      "\n",
      "Epoch : 762\n",
      " Time:14.0\n",
      "Generator Loss: 1.819628357887268 Discriminator Loss: 0.20382022857666016\n",
      "\n",
      "Epoch : 763\n",
      " Time:15.0\n",
      "Generator Loss: 5.197906970977783 Discriminator Loss: 0.583831250667572\n",
      "\n",
      "Epoch : 764\n",
      " Time:14.0\n",
      "Generator Loss: 3.931917190551758 Discriminator Loss: 0.04314500838518143\n",
      "\n",
      "Epoch : 765\n",
      " Time:15.0\n",
      "Generator Loss: 3.313690423965454 Discriminator Loss: 0.057190604507923126\n",
      "\n",
      "Epoch : 766\n",
      " Time:14.0\n",
      "Generator Loss: 1.901793360710144 Discriminator Loss: 0.18961764872074127\n",
      "\n",
      "Epoch : 767\n",
      " Time:14.0\n",
      "Generator Loss: 5.727339267730713 Discriminator Loss: 0.6905143857002258\n",
      "\n",
      "Epoch : 768\n",
      " Time:14.0\n",
      "Generator Loss: 0.9890690445899963 Discriminator Loss: 0.49513235688209534\n",
      "\n",
      "Epoch : 769\n",
      " Time:14.0\n",
      "Generator Loss: 7.006618499755859 Discriminator Loss: 1.0412200689315796\n",
      "\n",
      "Epoch : 770\n",
      " Time:15.0\n",
      "Generator Loss: 9.640087127685547 Discriminator Loss: 0.18386326730251312\n",
      "\n",
      "Epoch : 771\n",
      " Time:15.0\n",
      "Generator Loss: 3.512314558029175 Discriminator Loss: 0.0518370158970356\n",
      "\n",
      "Epoch : 772\n",
      " Time:15.0\n",
      "Generator Loss: 2.278064489364624 Discriminator Loss: 0.13422343134880066\n",
      "\n",
      "Epoch : 773\n",
      " Time:15.0\n",
      "Generator Loss: 3.036505699157715 Discriminator Loss: 0.17594756186008453\n",
      "\n",
      "Epoch : 774\n",
      " Time:15.0\n",
      "Generator Loss: 1.9955482482910156 Discriminator Loss: 0.2280670404434204\n",
      "\n",
      "Epoch : 775\n",
      " Time:15.0\n",
      "Generator Loss: 3.9864718914031982 Discriminator Loss: 0.38865819573402405\n",
      "\n",
      "Epoch : 776\n",
      " Time:14.0\n",
      "Generator Loss: 0.6751149296760559 Discriminator Loss: 0.745667576789856\n",
      "\n",
      "Epoch : 777\n",
      " Time:15.0\n",
      "Generator Loss: 9.490001678466797 Discriminator Loss: 1.4663153886795044\n",
      "\n",
      "Epoch : 778\n",
      " Time:15.0\n",
      "Generator Loss: 6.058675765991211 Discriminator Loss: 0.5304901003837585\n",
      "\n",
      "Epoch : 779\n",
      " Time:15.0\n",
      "Generator Loss: 3.9799556732177734 Discriminator Loss: 0.11998189985752106\n",
      "\n",
      "Epoch : 780\n",
      " Time:14.0\n",
      "Generator Loss: 2.192103624343872 Discriminator Loss: 0.15118899941444397\n",
      "\n",
      "Epoch : 781\n",
      " Time:15.0\n",
      "Generator Loss: 2.952700614929199 Discriminator Loss: 0.19072850048542023\n",
      "\n",
      "Epoch : 782\n",
      " Time:15.0\n",
      "Generator Loss: 3.1777491569519043 Discriminator Loss: 0.11892327666282654\n",
      "\n",
      "Epoch : 783\n",
      " Time:15.0\n",
      "Generator Loss: 4.436740875244141 Discriminator Loss: 0.04396145045757294\n",
      "\n",
      "Epoch : 784\n",
      " Time:15.0\n",
      "Generator Loss: 2.308284044265747 Discriminator Loss: 0.11935734748840332\n",
      "\n",
      "Epoch : 785\n",
      " Time:14.0\n",
      "Generator Loss: 3.7785916328430176 Discriminator Loss: 0.21910317242145538\n",
      "\n",
      "Epoch : 786\n",
      " Time:15.0\n",
      "Generator Loss: 1.4890815019607544 Discriminator Loss: 0.2955068051815033\n",
      "\n",
      "Epoch : 787\n",
      " Time:15.0\n",
      "Generator Loss: 4.328341484069824 Discriminator Loss: 0.6537036299705505\n",
      "\n",
      "Epoch : 788\n",
      " Time:15.0\n",
      "Generator Loss: 1.8589903116226196 Discriminator Loss: 0.20620708167552948\n",
      "\n",
      "Epoch : 789\n",
      " Time:15.0\n",
      "Generator Loss: 5.449620723724365 Discriminator Loss: 0.5024973750114441\n",
      "\n",
      "Epoch : 790\n",
      " Time:15.0\n",
      "Generator Loss: 6.216817855834961 Discriminator Loss: 0.018137294799089432\n",
      "\n",
      "Epoch : 791\n",
      " Time:14.0\n",
      "Generator Loss: 3.8801305294036865 Discriminator Loss: 0.03174431249499321\n",
      "\n",
      "Epoch : 792\n",
      " Time:15.0\n",
      "Generator Loss: 1.6074070930480957 Discriminator Loss: 0.23358920216560364\n",
      "\n",
      "Epoch : 793\n",
      " Time:15.0\n",
      "Generator Loss: 5.3417649269104 Discriminator Loss: 0.7318894863128662\n",
      "\n",
      "Epoch : 794\n",
      " Time:15.0\n",
      "Generator Loss: 3.7186999320983887 Discriminator Loss: 0.050160251557826996\n",
      "\n",
      "Epoch : 795\n",
      " Time:15.0\n",
      "Generator Loss: 4.10438346862793 Discriminator Loss: 0.04344009980559349\n",
      "\n",
      "Epoch : 796\n",
      " Time:14.0\n",
      "Generator Loss: 1.6345319747924805 Discriminator Loss: 0.23512586951255798\n",
      "\n",
      "Epoch : 797\n",
      " Time:14.0\n",
      "Generator Loss: 6.023891925811768 Discriminator Loss: 0.6769579648971558\n",
      "\n",
      "Epoch : 798\n",
      " Time:14.0\n",
      "Generator Loss: 2.3818154335021973 Discriminator Loss: 0.1424746960401535\n",
      "\n",
      "Epoch : 799\n",
      " Time:14.0\n",
      "Generator Loss: 4.2570481300354 Discriminator Loss: 0.32679298520088196\n",
      "\n",
      "Epoch : 800\n",
      " Time:15.0\n",
      "Generator Loss: 1.2986259460449219 Discriminator Loss: 0.3639734983444214\n",
      "\n",
      "Epoch : 801\n",
      " Time:15.0\n",
      "Generator Loss: 8.902780532836914 Discriminator Loss: 1.4747364521026611\n",
      "\n",
      "Epoch : 802\n",
      " Time:15.0\n",
      "Generator Loss: 4.438379287719727 Discriminator Loss: 0.14162859320640564\n",
      "\n",
      "Epoch : 803\n",
      " Time:16.0\n",
      "Generator Loss: 2.6116175651550293 Discriminator Loss: 0.0913417786359787\n",
      "\n",
      "Epoch : 804\n",
      " Time:15.0\n",
      "Generator Loss: 1.7012766599655151 Discriminator Loss: 0.25356346368789673\n",
      "\n",
      "Epoch : 805\n",
      " Time:15.0\n",
      "Generator Loss: 4.370881080627441 Discriminator Loss: 0.4843931198120117\n",
      "\n",
      "Epoch : 806\n",
      " Time:15.0\n",
      "Generator Loss: 1.0869289636611938 Discriminator Loss: 0.4406188726425171\n",
      "\n",
      "Epoch : 807\n",
      " Time:3214.0\n",
      "Generator Loss: 5.439682960510254 Discriminator Loss: 1.1200964450836182\n",
      "\n",
      "Epoch : 808\n",
      " Time:15.0\n",
      "Generator Loss: 2.970160961151123 Discriminator Loss: 0.34173423051834106\n",
      "\n",
      "Epoch : 809\n",
      " Time:15.0\n",
      "Generator Loss: 2.4567949771881104 Discriminator Loss: 0.17619448900222778\n",
      "\n",
      "Epoch : 810\n",
      " Time:15.0\n",
      "Generator Loss: 3.696985960006714 Discriminator Loss: 0.13547734916210175\n",
      "\n",
      "Epoch : 811\n",
      " Time:15.0\n",
      "Generator Loss: 3.855236768722534 Discriminator Loss: 0.05043429136276245\n",
      "\n",
      "Epoch : 812\n",
      " Time:15.0\n",
      "Generator Loss: 5.188315391540527 Discriminator Loss: 0.02236076071858406\n",
      "\n",
      "Epoch : 813\n",
      " Time:15.0\n",
      "Generator Loss: 2.076218605041504 Discriminator Loss: 0.1491730660200119\n",
      "\n",
      "Epoch : 814\n",
      " Time:15.0\n",
      "Generator Loss: 3.949883460998535 Discriminator Loss: 0.3146587312221527\n",
      "\n",
      "Epoch : 815\n",
      " Time:15.0\n",
      "Generator Loss: 0.9521700143814087 Discriminator Loss: 0.5657485127449036\n",
      "\n",
      "Epoch : 816\n",
      " Time:15.0\n",
      "Generator Loss: 4.905491828918457 Discriminator Loss: 1.5503599643707275\n",
      "\n",
      "Epoch : 817\n",
      " Time:15.0\n",
      "Generator Loss: 4.549298286437988 Discriminator Loss: 0.5993337631225586\n",
      "\n",
      "Epoch : 818\n",
      " Time:15.0\n",
      "Generator Loss: 3.029784679412842 Discriminator Loss: 0.12256599962711334\n",
      "\n",
      "Epoch : 819\n",
      " Time:15.0\n",
      "Generator Loss: 2.0423922538757324 Discriminator Loss: 0.17782466113567352\n",
      "\n",
      "Epoch : 820\n",
      " Time:15.0\n",
      "Generator Loss: 4.44840669631958 Discriminator Loss: 0.3713735342025757\n",
      "\n",
      "Epoch : 821\n",
      " Time:15.0\n",
      "Generator Loss: 4.506854057312012 Discriminator Loss: 0.03126627206802368\n",
      "\n",
      "Epoch : 822\n",
      " Time:15.0\n",
      "Generator Loss: 4.121212005615234 Discriminator Loss: 0.030827602371573448\n",
      "\n",
      "Epoch : 823\n",
      " Time:14.0\n",
      "Generator Loss: 1.8033168315887451 Discriminator Loss: 0.19093698263168335\n",
      "\n",
      "Epoch : 824\n",
      " Time:15.0\n",
      "Generator Loss: 4.239828586578369 Discriminator Loss: 0.44583839178085327\n",
      "\n",
      "Epoch : 825\n",
      " Time:15.0\n",
      "Generator Loss: 3.6857964992523193 Discriminator Loss: 0.05007678270339966\n",
      "\n",
      "Epoch : 826\n",
      " Time:15.0\n",
      "Generator Loss: 3.2365901470184326 Discriminator Loss: 0.0664176195859909\n",
      "\n",
      "Epoch : 827\n",
      " Time:15.0\n",
      "Generator Loss: 1.977957844734192 Discriminator Loss: 0.1784677654504776\n",
      "\n",
      "Epoch : 828\n",
      " Time:15.0\n",
      "Generator Loss: 5.842533111572266 Discriminator Loss: 0.3537186086177826\n",
      "\n",
      "Epoch : 829\n",
      " Time:15.0\n",
      "Generator Loss: 2.7981576919555664 Discriminator Loss: 0.08493918180465698\n",
      "\n",
      "Epoch : 830\n",
      " Time:15.0\n",
      "Generator Loss: 3.0080666542053223 Discriminator Loss: 0.13603977859020233\n",
      "\n",
      "Epoch : 831\n",
      " Time:15.0\n",
      "Generator Loss: 1.4917709827423096 Discriminator Loss: 0.31377193331718445\n",
      "\n",
      "Epoch : 832\n",
      " Time:15.0\n",
      "Generator Loss: 7.749384880065918 Discriminator Loss: 1.0451414585113525\n",
      "\n",
      "Epoch : 833\n",
      " Time:15.0\n",
      "Generator Loss: 4.459377765655518 Discriminator Loss: 0.05912384018301964\n",
      "\n",
      "Epoch : 834\n",
      " Time:15.0\n",
      "Generator Loss: 3.845012903213501 Discriminator Loss: 0.03330276161432266\n",
      "\n",
      "Epoch : 835\n",
      " Time:15.0\n",
      "Generator Loss: 1.721058964729309 Discriminator Loss: 0.2130986601114273\n",
      "\n",
      "Epoch : 836\n",
      " Time:15.0\n",
      "Generator Loss: 5.422089576721191 Discriminator Loss: 0.6450532078742981\n",
      "\n",
      "Epoch : 837\n",
      " Time:15.0\n",
      "Generator Loss: 1.2044663429260254 Discriminator Loss: 0.3834402859210968\n",
      "\n",
      "Epoch : 838\n",
      " Time:15.0\n",
      "Generator Loss: 4.759625434875488 Discriminator Loss: 1.1582974195480347\n",
      "\n",
      "Epoch : 839\n",
      " Time:15.0\n",
      "Generator Loss: 4.019625663757324 Discriminator Loss: 0.2473202645778656\n",
      "\n",
      "Epoch : 840\n",
      " Time:15.0\n",
      "Generator Loss: 3.9852805137634277 Discriminator Loss: 0.044258393347263336\n",
      "\n",
      "Epoch : 841\n",
      " Time:15.0\n",
      "Generator Loss: 1.3934319019317627 Discriminator Loss: 0.31260234117507935\n",
      "\n",
      "Epoch : 842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Time:15.0\n",
      "Generator Loss: 6.599607467651367 Discriminator Loss: 0.9852959513664246\n",
      "\n",
      "Epoch : 843\n",
      " Time:15.0\n",
      "Generator Loss: 6.022464275360107 Discriminator Loss: 0.10207097232341766\n",
      "\n",
      "Epoch : 844\n",
      " Time:15.0\n",
      "Generator Loss: 4.080843925476074 Discriminator Loss: 0.03080473653972149\n",
      "\n",
      "Epoch : 845\n",
      " Time:15.0\n",
      "Generator Loss: 1.4001119136810303 Discriminator Loss: 0.2987273931503296\n",
      "\n",
      "Epoch : 846\n",
      " Time:15.0\n",
      "Generator Loss: 4.753968238830566 Discriminator Loss: 0.550150454044342\n",
      "\n",
      "Epoch : 847\n",
      " Time:15.0\n",
      "Generator Loss: 3.4952316284179688 Discriminator Loss: 0.057971689850091934\n",
      "\n",
      "Epoch : 848\n",
      " Time:15.0\n",
      "Generator Loss: 4.729650974273682 Discriminator Loss: 0.04319163039326668\n",
      "\n",
      "Epoch : 849\n",
      " Time:15.0\n",
      "Generator Loss: 1.9186744689941406 Discriminator Loss: 0.17486265301704407\n",
      "\n",
      "Epoch : 850\n",
      " Time:15.0\n",
      "Generator Loss: 4.422575950622559 Discriminator Loss: 0.3055831789970398\n",
      "\n",
      "Epoch : 851\n",
      " Time:15.0\n",
      "Generator Loss: 1.7287484407424927 Discriminator Loss: 0.23230823874473572\n",
      "\n",
      "Epoch : 852\n",
      " Time:15.0\n",
      "Generator Loss: 4.608248710632324 Discriminator Loss: 0.6023531556129456\n",
      "\n",
      "Epoch : 853\n",
      " Time:15.0\n",
      "Generator Loss: 1.8536561727523804 Discriminator Loss: 0.1880655735731125\n",
      "\n",
      "Epoch : 854\n",
      " Time:16.0\n",
      "Generator Loss: 4.465014934539795 Discriminator Loss: 0.4394562542438507\n",
      "\n",
      "Epoch : 855\n",
      " Time:16.0\n",
      "Generator Loss: 4.521870136260986 Discriminator Loss: 0.02316863462328911\n",
      "\n",
      "Epoch : 856\n",
      " Time:16.0\n",
      "Generator Loss: 4.947075366973877 Discriminator Loss: 0.016851266846060753\n",
      "\n",
      "Epoch : 857\n",
      " Time:15.0\n",
      "Generator Loss: 1.178713321685791 Discriminator Loss: 0.3864867389202118\n",
      "\n",
      "Epoch : 858\n",
      " Time:15.0\n",
      "Generator Loss: 7.916879653930664 Discriminator Loss: 1.0512597560882568\n",
      "\n",
      "Epoch : 859\n",
      " Time:15.0\n",
      "Generator Loss: 6.2235517501831055 Discriminator Loss: 0.12563090026378632\n",
      "\n",
      "Epoch : 860\n",
      " Time:15.0\n",
      "Generator Loss: 3.584960460662842 Discriminator Loss: 0.04154089838266373\n",
      "\n",
      "Epoch : 861\n",
      " Time:15.0\n",
      "Generator Loss: 2.4660775661468506 Discriminator Loss: 0.11572244018316269\n",
      "\n",
      "Epoch : 862\n",
      " Time:15.0\n",
      "Generator Loss: 4.144189834594727 Discriminator Loss: 0.09036839008331299\n",
      "\n",
      "Epoch : 863\n",
      " Time:15.0\n",
      "Generator Loss: 3.3590736389160156 Discriminator Loss: 0.05523040518164635\n",
      "\n",
      "Epoch : 864\n",
      " Time:15.0\n",
      "Generator Loss: 5.167153358459473 Discriminator Loss: 0.024193963035941124\n",
      "\n",
      "Epoch : 865\n",
      " Time:16.0\n",
      "Generator Loss: 1.7559549808502197 Discriminator Loss: 0.20294010639190674\n",
      "\n",
      "Epoch : 866\n",
      " Time:17.0\n",
      "Generator Loss: 6.365579605102539 Discriminator Loss: 0.7310171127319336\n",
      "\n",
      "Epoch : 867\n",
      " Time:16.0\n",
      "Generator Loss: 2.366252899169922 Discriminator Loss: 0.11908967792987823\n",
      "\n",
      "Epoch : 868\n",
      " Time:16.0\n",
      "Generator Loss: 3.7929794788360596 Discriminator Loss: 0.34052804112434387\n",
      "\n",
      "Epoch : 869\n",
      " Time:16.0\n",
      "Generator Loss: 1.2842973470687866 Discriminator Loss: 0.34105607867240906\n",
      "\n",
      "Epoch : 870\n",
      " Time:16.0\n",
      "Generator Loss: 4.939393997192383 Discriminator Loss: 0.9260292053222656\n",
      "\n",
      "Epoch : 871\n",
      " Time:16.0\n",
      "Generator Loss: 2.928449869155884 Discriminator Loss: 0.10640356689691544\n",
      "\n",
      "Epoch : 872\n",
      " Time:16.0\n",
      "Generator Loss: 1.8507658243179321 Discriminator Loss: 0.23335644602775574\n",
      "\n",
      "Epoch : 873\n",
      " Time:16.0\n",
      "Generator Loss: 6.100191116333008 Discriminator Loss: 0.9945512413978577\n",
      "\n",
      "Epoch : 874\n",
      " Time:16.0\n",
      "Generator Loss: 1.6152580976486206 Discriminator Loss: 0.2646431028842926\n",
      "\n",
      "Epoch : 875\n",
      " Time:16.0\n",
      "Generator Loss: 4.149288177490234 Discriminator Loss: 0.6705995202064514\n",
      "\n",
      "Epoch : 876\n",
      " Time:16.0\n",
      "Generator Loss: 2.733071804046631 Discriminator Loss: 0.11493541300296783\n",
      "\n",
      "Epoch : 877\n",
      " Time:15.0\n",
      "Generator Loss: 3.668935537338257 Discriminator Loss: 0.10867661982774734\n",
      "\n",
      "Epoch : 878\n",
      " Time:16.0\n",
      "Generator Loss: 1.7871187925338745 Discriminator Loss: 0.21686023473739624\n",
      "\n",
      "Epoch : 879\n",
      " Time:16.0\n",
      "Generator Loss: 4.231029510498047 Discriminator Loss: 0.5246567130088806\n",
      "\n",
      "Epoch : 880\n",
      " Time:16.0\n",
      "Generator Loss: 2.0829548835754395 Discriminator Loss: 0.15618908405303955\n",
      "\n",
      "Epoch : 881\n",
      " Time:15.0\n",
      "Generator Loss: 4.8242363929748535 Discriminator Loss: 0.40168651938438416\n",
      "\n",
      "Epoch : 882\n",
      " Time:16.0\n",
      "Generator Loss: 2.2285637855529785 Discriminator Loss: 0.13318610191345215\n",
      "\n",
      "Epoch : 883\n",
      " Time:15.0\n",
      "Generator Loss: 3.387895107269287 Discriminator Loss: 0.29895856976509094\n",
      "\n",
      "Epoch : 884\n",
      " Time:16.0\n",
      "Generator Loss: 3.0219039916992188 Discriminator Loss: 0.07934500277042389\n",
      "\n",
      "Epoch : 885\n",
      " Time:16.0\n",
      "Generator Loss: 4.615994453430176 Discriminator Loss: 0.03720702603459358\n",
      "\n",
      "Epoch : 886\n",
      " Time:16.0\n",
      "Generator Loss: 1.299593210220337 Discriminator Loss: 0.3325352966785431\n",
      "\n",
      "Epoch : 887\n",
      " Time:16.0\n",
      "Generator Loss: 7.167452812194824 Discriminator Loss: 1.1292476654052734\n",
      "\n",
      "Epoch : 888\n",
      " Time:16.0\n",
      "Generator Loss: 2.695375919342041 Discriminator Loss: 0.1963525116443634\n",
      "\n",
      "Epoch : 889\n",
      " Time:16.0\n",
      "Generator Loss: 1.6077101230621338 Discriminator Loss: 0.2997570037841797\n",
      "\n",
      "Epoch : 890\n",
      " Time:16.0\n",
      "Generator Loss: 4.905608654022217 Discriminator Loss: 0.5634265542030334\n",
      "\n",
      "Epoch : 891\n",
      " Time:16.0\n",
      "Generator Loss: 2.517669200897217 Discriminator Loss: 0.12692685425281525\n",
      "\n",
      "Epoch : 892\n",
      " Time:16.0\n",
      "Generator Loss: 4.97456169128418 Discriminator Loss: 0.1836376041173935\n",
      "\n",
      "Epoch : 893\n",
      " Time:17.0\n",
      "Generator Loss: 1.9072699546813965 Discriminator Loss: 0.18438971042633057\n",
      "\n",
      "Epoch : 894\n",
      " Time:18.0\n",
      "Generator Loss: 5.090996742248535 Discriminator Loss: 0.32229432463645935\n",
      "\n",
      "Epoch : 895\n",
      " Time:18.0\n",
      "Generator Loss: 3.430572748184204 Discriminator Loss: 0.04748467355966568\n",
      "\n",
      "Epoch : 896\n",
      " Time:18.0\n",
      "Generator Loss: 3.1396424770355225 Discriminator Loss: 0.06311118602752686\n",
      "\n",
      "Epoch : 897\n",
      " Time:18.0\n",
      "Generator Loss: 1.0353325605392456 Discriminator Loss: 0.4824201762676239\n",
      "\n",
      "Epoch : 898\n",
      " Time:18.0\n",
      "Generator Loss: 10.407344818115234 Discriminator Loss: 1.4281789064407349\n",
      "\n",
      "Epoch : 899\n",
      " Time:19.0\n",
      "Generator Loss: 7.2896013259887695 Discriminator Loss: 0.3844800293445587\n",
      "\n",
      "Epoch : 900\n",
      " Time:18.0\n",
      "Generator Loss: 4.9728803634643555 Discriminator Loss: 0.05060938000679016\n",
      "\n",
      "Epoch : 901\n",
      " Time:18.0\n",
      "Generator Loss: 1.6807111501693726 Discriminator Loss: 0.22362230718135834\n",
      "\n",
      "Epoch : 902\n",
      " Time:18.0\n",
      "Generator Loss: 3.0657429695129395 Discriminator Loss: 0.38167279958724976\n",
      "\n",
      "Epoch : 903\n",
      " Time:18.0\n",
      "Generator Loss: 1.8906569480895996 Discriminator Loss: 0.21605849266052246\n",
      "\n",
      "Epoch : 904\n",
      " Time:18.0\n",
      "Generator Loss: 5.191047191619873 Discriminator Loss: 0.5436086654663086\n",
      "\n",
      "Epoch : 905\n",
      " Time:18.0\n",
      "Generator Loss: 0.8045133948326111 Discriminator Loss: 0.6292614936828613\n",
      "\n",
      "Epoch : 906\n",
      " Time:18.0\n",
      "Generator Loss: 8.104305267333984 Discriminator Loss: 1.2096946239471436\n",
      "\n",
      "Epoch : 907\n",
      " Time:18.0\n",
      "Generator Loss: 7.682310104370117 Discriminator Loss: 0.3948209285736084\n",
      "\n",
      "Epoch : 908\n",
      " Time:18.0\n",
      "Generator Loss: 3.4463369846343994 Discriminator Loss: 0.10855069011449814\n",
      "\n",
      "Epoch : 909\n",
      " Time:18.0\n",
      "Generator Loss: 2.004188060760498 Discriminator Loss: 0.18259891867637634\n",
      "\n",
      "Epoch : 910\n",
      " Time:18.0\n",
      "Generator Loss: 3.030233383178711 Discriminator Loss: 0.23289354145526886\n",
      "\n",
      "Epoch : 911\n",
      " Time:18.0\n",
      "Generator Loss: 1.666661024093628 Discriminator Loss: 0.26012980937957764\n",
      "\n",
      "Epoch : 912\n",
      " Time:19.0\n",
      "Generator Loss: 3.676994562149048 Discriminator Loss: 0.30992037057876587\n",
      "\n",
      "Epoch : 913\n",
      " Time:17.0\n",
      "Generator Loss: 1.8420093059539795 Discriminator Loss: 0.2089025378227234\n",
      "\n",
      "Epoch : 914\n",
      " Time:17.0\n",
      "Generator Loss: 3.985416889190674 Discriminator Loss: 0.3014896512031555\n",
      "\n",
      "Epoch : 915\n",
      " Time:18.0\n",
      "Generator Loss: 2.507768392562866 Discriminator Loss: 0.10655863583087921\n",
      "\n",
      "Epoch : 916\n",
      " Time:18.0\n",
      "Generator Loss: 4.136754989624023 Discriminator Loss: 0.0962793380022049\n",
      "\n",
      "Epoch : 917\n",
      " Time:18.0\n",
      "Generator Loss: 2.0604302883148193 Discriminator Loss: 0.1549004167318344\n",
      "\n",
      "Epoch : 918\n",
      " Time:18.0\n",
      "Generator Loss: 4.676697254180908 Discriminator Loss: 0.3141373097896576\n",
      "\n",
      "Epoch : 919\n",
      " Time:18.0\n",
      "Generator Loss: 0.7874672412872314 Discriminator Loss: 0.6271443367004395\n",
      "\n",
      "Epoch : 920\n",
      " Time:18.0\n",
      "Generator Loss: 8.337400436401367 Discriminator Loss: 1.1383283138275146\n",
      "\n",
      "Epoch : 921\n",
      " Time:18.0\n",
      "Generator Loss: 4.748532295227051 Discriminator Loss: 0.37360528111457825\n",
      "\n",
      "Epoch : 922\n",
      " Time:18.0\n",
      "Generator Loss: 4.539837837219238 Discriminator Loss: 0.06876116991043091\n",
      "\n",
      "Epoch : 923\n",
      " Time:18.0\n",
      "Generator Loss: 2.049396514892578 Discriminator Loss: 0.1617303341627121\n",
      "\n",
      "Epoch : 924\n",
      " Time:18.0\n",
      "Generator Loss: 2.9248030185699463 Discriminator Loss: 0.2017914056777954\n",
      "\n",
      "Epoch : 925\n",
      " Time:18.0\n",
      "Generator Loss: 1.5665837526321411 Discriminator Loss: 0.3072500228881836\n",
      "\n",
      "Epoch : 926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Time:17.0\n",
      "Generator Loss: 4.393890380859375 Discriminator Loss: 0.56058669090271\n",
      "\n",
      "Epoch : 927\n",
      " Time:16.0\n",
      "Generator Loss: 2.2398948669433594 Discriminator Loss: 0.1623936891555786\n",
      "\n",
      "Epoch : 928\n",
      " Time:17.0\n",
      "Generator Loss: 4.291429042816162 Discriminator Loss: 0.21441195905208588\n",
      "\n",
      "Epoch : 929\n",
      " Time:18.0\n",
      "Generator Loss: 1.820797085762024 Discriminator Loss: 0.19262245297431946\n",
      "\n",
      "Epoch : 930\n",
      " Time:18.0\n",
      "Generator Loss: 4.459321975708008 Discriminator Loss: 0.5552783608436584\n",
      "\n",
      "Epoch : 931\n",
      " Time:18.0\n",
      "Generator Loss: 7.388616561889648 Discriminator Loss: 0.008126970380544662\n",
      "\n",
      "Epoch : 932\n",
      " Time:18.0\n",
      "Generator Loss: 3.916309356689453 Discriminator Loss: 0.027012303471565247\n",
      "\n",
      "Epoch : 933\n",
      " Time:19.0\n",
      "Generator Loss: 1.3350896835327148 Discriminator Loss: 0.33760547637939453\n",
      "\n",
      "Epoch : 934\n",
      " Time:18.0\n",
      "Generator Loss: 6.783910751342773 Discriminator Loss: 0.8988009095191956\n",
      "\n",
      "Epoch : 935\n",
      " Time:18.0\n",
      "Generator Loss: 5.13129997253418 Discriminator Loss: 0.08520805090665817\n",
      "\n",
      "Epoch : 936\n",
      " Time:18.0\n",
      "Generator Loss: 4.765105724334717 Discriminator Loss: 0.019714023917913437\n",
      "\n",
      "Epoch : 937\n",
      " Time:17.0\n",
      "Generator Loss: 1.3485901355743408 Discriminator Loss: 0.3166356384754181\n",
      "\n",
      "Epoch : 938\n",
      " Time:17.0\n",
      "Generator Loss: 5.267984867095947 Discriminator Loss: 0.7271924614906311\n",
      "\n",
      "Epoch : 939\n",
      " Time:16.0\n",
      "Generator Loss: 2.464982509613037 Discriminator Loss: 0.14399302005767822\n",
      "\n",
      "Epoch : 940\n",
      " Time:16.0\n",
      "Generator Loss: 4.633449077606201 Discriminator Loss: 0.1922731101512909\n",
      "\n",
      "Epoch : 941\n",
      " Time:17.0\n",
      "Generator Loss: 1.6375436782836914 Discriminator Loss: 0.22909408807754517\n",
      "\n",
      "Epoch : 942\n",
      " Time:18.0\n",
      "Generator Loss: 4.428652286529541 Discriminator Loss: 0.4488418996334076\n",
      "\n",
      "Epoch : 943\n",
      " Time:19.0\n",
      "Generator Loss: 4.568170547485352 Discriminator Loss: 0.025837715715169907\n",
      "\n",
      "Epoch : 944\n",
      " Time:17.0\n",
      "Generator Loss: 4.893808841705322 Discriminator Loss: 0.018758919090032578\n",
      "\n",
      "Epoch : 945\n",
      " Time:17.0\n",
      "Generator Loss: 2.1082887649536133 Discriminator Loss: 0.1410716474056244\n",
      "\n",
      "Epoch : 946\n",
      " Time:18.0\n",
      "Generator Loss: 5.0598464012146 Discriminator Loss: 0.27292168140411377\n",
      "\n",
      "Epoch : 947\n",
      " Time:19.0\n",
      "Generator Loss: 1.1316627264022827 Discriminator Loss: 0.40683451294898987\n",
      "\n",
      "Epoch : 948\n",
      " Time:19.0\n",
      "Generator Loss: 5.977008819580078 Discriminator Loss: 1.0887004137039185\n",
      "\n",
      "Epoch : 949\n",
      " Time:18.0\n",
      "Generator Loss: 3.618124485015869 Discriminator Loss: 0.15991267561912537\n",
      "\n",
      "Epoch : 950\n",
      " Time:18.0\n",
      "Generator Loss: 3.196791648864746 Discriminator Loss: 0.059478189796209335\n",
      "\n",
      "Epoch : 951\n",
      " Time:17.0\n",
      "Generator Loss: 3.094102382659912 Discriminator Loss: 0.07978092133998871\n",
      "\n",
      "Epoch : 952\n",
      " Time:18.0\n",
      "Generator Loss: 4.79335880279541 Discriminator Loss: 0.04653192311525345\n",
      "\n",
      "Epoch : 953\n",
      " Time:18.0\n",
      "Generator Loss: 2.1417531967163086 Discriminator Loss: 0.14398939907550812\n",
      "\n",
      "Epoch : 954\n",
      " Time:18.0\n",
      "Generator Loss: 6.104462146759033 Discriminator Loss: 0.5795374512672424\n",
      "\n",
      "Epoch : 955\n",
      " Time:16.0\n",
      "Generator Loss: 1.1264419555664062 Discriminator Loss: 0.4277552664279938\n",
      "\n",
      "Epoch : 956\n",
      " Time:16.0\n",
      "Generator Loss: 7.78367805480957 Discriminator Loss: 1.2691564559936523\n",
      "\n",
      "Epoch : 957\n",
      " Time:17.0\n",
      "Generator Loss: 5.699674606323242 Discriminator Loss: 0.3192967176437378\n",
      "\n",
      "Epoch : 958\n",
      " Time:18.0\n",
      "Generator Loss: 1.9862492084503174 Discriminator Loss: 0.17259886860847473\n",
      "\n",
      "Epoch : 959\n",
      " Time:18.0\n",
      "Generator Loss: 3.066617727279663 Discriminator Loss: 0.31261569261550903\n",
      "\n",
      "Epoch : 960\n",
      " Time:17.0\n",
      "Generator Loss: 2.7657523155212402 Discriminator Loss: 0.08710825443267822\n",
      "\n",
      "Epoch : 961\n",
      " Time:19.0\n",
      "Generator Loss: 2.630277633666992 Discriminator Loss: 0.1409073919057846\n",
      "\n",
      "Epoch : 962\n",
      " Time:18.0\n",
      "Generator Loss: 1.7361608743667603 Discriminator Loss: 0.26949822902679443\n",
      "\n",
      "Epoch : 963\n",
      " Time:17.0\n",
      "Generator Loss: 4.980305194854736 Discriminator Loss: 0.6501986384391785\n",
      "\n",
      "Epoch : 964\n",
      " Time:18.0\n",
      "Generator Loss: 1.3494807481765747 Discriminator Loss: 0.32193875312805176\n",
      "\n",
      "Epoch : 965\n",
      " Time:18.0\n",
      "Generator Loss: 5.428165435791016 Discriminator Loss: 0.8417713046073914\n",
      "\n",
      "Epoch : 966\n",
      " Time:18.0\n",
      "Generator Loss: 2.953946590423584 Discriminator Loss: 0.16234475374221802\n",
      "\n",
      "Epoch : 967\n",
      " Time:18.0\n",
      "Generator Loss: 2.6482863426208496 Discriminator Loss: 0.12453912198543549\n",
      "\n",
      "Epoch : 968\n",
      " Time:18.0\n",
      "Generator Loss: 3.0629169940948486 Discriminator Loss: 0.18273687362670898\n",
      "\n",
      "Epoch : 969\n",
      " Time:18.0\n",
      "Generator Loss: 0.9821138978004456 Discriminator Loss: 0.503544807434082\n",
      "\n",
      "Epoch : 970\n",
      " Time:18.0\n",
      "Generator Loss: 9.01887035369873 Discriminator Loss: 1.2303252220153809\n",
      "\n",
      "Epoch : 971\n",
      " Time:18.0\n",
      "Generator Loss: 6.243975639343262 Discriminator Loss: 0.37177976965904236\n",
      "\n",
      "Epoch : 972\n",
      " Time:18.0\n",
      "Generator Loss: 3.8321168422698975 Discriminator Loss: 0.08229982852935791\n",
      "\n",
      "Epoch : 973\n",
      " Time:18.0\n",
      "Generator Loss: 1.9448599815368652 Discriminator Loss: 0.18663984537124634\n",
      "\n",
      "Epoch : 974\n",
      " Time:18.0\n",
      "Generator Loss: 3.843000888824463 Discriminator Loss: 0.24332985281944275\n",
      "\n",
      "Epoch : 975\n",
      " Time:18.0\n",
      "Generator Loss: 1.1512014865875244 Discriminator Loss: 0.4249870181083679\n",
      "\n",
      "Epoch : 976\n",
      " Time:18.0\n",
      "Generator Loss: 5.265582084655762 Discriminator Loss: 0.7095127701759338\n",
      "\n",
      "Epoch : 977\n",
      " Time:18.0\n",
      "Generator Loss: 3.4413437843322754 Discriminator Loss: 0.1478751301765442\n",
      "\n",
      "Epoch : 978\n",
      " Time:18.0\n",
      "Generator Loss: 5.560348987579346 Discriminator Loss: 0.04718158766627312\n",
      "\n",
      "Epoch : 979\n",
      " Time:18.0\n",
      "Generator Loss: 1.732945203781128 Discriminator Loss: 0.21045483648777008\n",
      "\n",
      "Epoch : 980\n",
      " Time:19.0\n",
      "Generator Loss: 3.6731252670288086 Discriminator Loss: 0.3727463483810425\n",
      "\n",
      "Epoch : 981\n",
      " Time:18.0\n",
      "Generator Loss: 2.6395070552825928 Discriminator Loss: 0.09818994253873825\n",
      "\n",
      "Epoch : 982\n",
      " Time:18.0\n",
      "Generator Loss: 5.165820121765137 Discriminator Loss: 0.16612708568572998\n",
      "\n",
      "Epoch : 983\n",
      " Time:18.0\n",
      "Generator Loss: 2.094729423522949 Discriminator Loss: 0.14277790486812592\n",
      "\n",
      "Epoch : 984\n",
      " Time:18.0\n",
      "Generator Loss: 3.4920835494995117 Discriminator Loss: 0.26433610916137695\n",
      "\n",
      "Epoch : 985\n",
      " Time:17.0\n",
      "Generator Loss: 2.9334726333618164 Discriminator Loss: 0.06946758925914764\n",
      "\n",
      "Epoch : 986\n",
      " Time:18.0\n",
      "Generator Loss: 4.677150249481201 Discriminator Loss: 0.037999462336301804\n",
      "\n",
      "Epoch : 987\n",
      " Time:18.0\n",
      "Generator Loss: 3.4137799739837646 Discriminator Loss: 0.0421622134745121\n",
      "\n",
      "Epoch : 988\n",
      " Time:18.0\n",
      "Generator Loss: 3.5224952697753906 Discriminator Loss: 0.04350261762738228\n",
      "\n",
      "Epoch : 989\n",
      " Time:18.0\n",
      "Generator Loss: 3.0273988246917725 Discriminator Loss: 0.08273939788341522\n",
      "\n",
      "Epoch : 990\n",
      " Time:18.0\n",
      "Generator Loss: 5.62811279296875 Discriminator Loss: 0.10275813937187195\n",
      "\n",
      "Epoch : 991\n",
      " Time:18.0\n",
      "Generator Loss: 1.8327019214630127 Discriminator Loss: 0.18302404880523682\n",
      "\n",
      "Epoch : 992\n",
      " Time:18.0\n",
      "Generator Loss: 5.681988716125488 Discriminator Loss: 0.6484736800193787\n",
      "\n",
      "Epoch : 993\n",
      " Time:18.0\n",
      "Generator Loss: 6.3907976150512695 Discriminator Loss: 0.006569093093276024\n",
      "\n",
      "Epoch : 994\n",
      " Time:18.0\n",
      "Generator Loss: 1.7617499828338623 Discriminator Loss: 0.20567670464515686\n",
      "\n",
      "Epoch : 995\n",
      " Time:18.0\n",
      "Generator Loss: 4.426033973693848 Discriminator Loss: 0.6072403788566589\n",
      "\n",
      "Epoch : 996\n",
      " Time:18.0\n",
      "Generator Loss: 6.520595550537109 Discriminator Loss: 0.014566032215952873\n",
      "\n",
      "Epoch : 997\n",
      " Time:18.0\n",
      "Generator Loss: 3.04400897026062 Discriminator Loss: 0.05996700003743172\n",
      "\n",
      "Epoch : 998\n",
      " Time:18.0\n",
      "Generator Loss: 2.4745893478393555 Discriminator Loss: 0.11471359431743622\n",
      "\n",
      "Epoch : 999\n",
      " Time:18.0\n",
      "Generator Loss: 4.0019049644470215 Discriminator Loss: 0.257343053817749\n",
      "\n",
      "Epoch : 1000\n",
      " Time:18.0\n",
      "Generator Loss: 0.31094682216644287 Discriminator Loss: 1.358712911605835\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akagg\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "\n",
    "\n",
    "\n",
    "# to get the files in proper order\n",
    "def sorted_alphanumeric(data):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n",
    "    return sorted(data,key = alphanum_key)\n",
    "# defining the size of the image\n",
    "SIZE = 128\n",
    "_img = []\n",
    "path = r'C:\\Users\\akagg\\Downloads\\archive\\Dataset\\Train\\Fake1'\n",
    "\n",
    "files = os.listdir(path)\n",
    "files = sorted_alphanumeric(files)\n",
    "for i in tqdm(files):\n",
    "        \n",
    "        img = cv2.imread(path + '/'+i,1)\n",
    "        # open cv reads images in BGR format so we have to convert it to RGB\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        #resizing image\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = (img - 127.5) / 127.5\n",
    "        imh = img.astype(float)\n",
    "        _img.append(img_to_array(img))\n",
    "# Batch size and dataset\n",
    "batch_size = 32\n",
    "dataset=tf.data.Dataset.from_tensor_slices(np.array(_img)).batch(batch_size)\n",
    "# Generator\n",
    "latent_dim = 100\n",
    "def Generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(128*128*3, use_bias=False, input_shape=(latent_dim,)))\n",
    "    model.add(layers.Reshape((128,128,3)))\n",
    "    # downsampling\n",
    "    model.add(tf.keras.layers.Conv2D(128,4, strides=1, padding='same',kernel_initializer='he_normal', use_bias=False))\n",
    "    model.add(tf.keras.layers.Conv2D(128,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    model.add(tf.keras.layers.Conv2D(256,4, strides=1, padding='same',kernel_initializer='he_normal', use_bias=False))\n",
    "    model.add(tf.keras.layers.Conv2D(256,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(512, 4, strides=1,padding='same',kernel_initializer='he_normal',use_bias=False))\n",
    "    model.add(tf.keras.layers.Conv2D(512,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n",
    "\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    #upsampling\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(512, 4, strides=1,padding='same',kernel_initializer='he_normal',use_bias=False))\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(512, 4, strides=2,padding='same',kernel_initializer='he_normal',use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(256, 4, strides=1,padding='same',kernel_initializer='he_normal',use_bias=False))\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(256, 4, strides=2,padding='same',kernel_initializer='he_normal',use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(128, 4, strides=2,padding='same',kernel_initializer='he_normal',use_bias=False))\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(128, 4, strides=1,padding='same',kernel_initializer='he_normal',use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(3,4,strides = 1, padding = 'same',activation = 'tanh'))\n",
    "\n",
    "\n",
    "\n",
    "    return model\n",
    "# Generator created\n",
    "generator = Generator()\n",
    "generator.summary()\n",
    "# Discrimitor\n",
    "\n",
    "def Discriminator():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input((SIZE, SIZE, 3)))\n",
    "    model.add(tf.keras.layers.Conv2D(128,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    model.add(tf.keras.layers.Conv2D(128,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    model.add(tf.keras.layers.Conv2D(256,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    model.add(tf.keras.layers.Conv2D(256,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    model.add(tf.keras.layers.Conv2D(512,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(1,activation = 'sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Discrimitor Created\n",
    "discriminator = Discriminator()\n",
    "discriminator.summary()\n",
    "\n",
    "noise = np.random.normal(-1,1,(1,100))\n",
    "img = generator(noise)\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.RMSprop(\n",
    "        lr=.0001,\n",
    "        clipvalue=1.0,\n",
    "        decay=1e-8\n",
    "    )\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output),fake_output)\n",
    "def discriminator_loss(fake_output, real_output):\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output),fake_output)\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output),real_output)\n",
    "    return fake_loss + real_loss\n",
    "\n",
    "def train_steps(images):\n",
    "    noise = np.random.normal(0,1,(batch_size,latent_dim))\n",
    "    with tf.GradientTape() as gen_tape , tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise)\n",
    "        fake_output = discriminator(generated_images)\n",
    "        real_output = discriminator(images)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        dis_loss = discriminator_loss(fake_output, real_output)\n",
    "\n",
    "\n",
    "    gradient_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradient_of_discriminator = disc_tape.gradient(dis_loss, discriminator.trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradient_of_generator,generator.trainable_variables))\n",
    "    optimizer.apply_gradients(zip(gradient_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    loss = {'gen loss':gen_loss,\n",
    "           'disc loss': dis_loss}\n",
    "    return loss\n",
    "import time\n",
    "def train(epochs,dataset):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        print(\"\\nEpoch : {}\".format(epoch + 1))\n",
    "        for images in dataset:\n",
    "            loss = train_steps(images)\n",
    "        print(\" Time:{}\".format(np.round(time.time() - start),2))\n",
    "        print(\"Generator Loss: {} Discriminator Loss: {}\".format(loss['gen loss'],loss['disc loss']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train(1000,dataset)\n",
    "generator.save('generator.h5')\n",
    "discriminator.save(\"discriminator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf597cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\akagg'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5931b27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026603FC4A40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026603FC4A40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "generator = load_model(r'C:\\Users\\akagg\\Downloads\\archive\\Dataset\\Deepfake\\generator.h5')\n",
    "\n",
    "# Function to generate images\n",
    "def generate_images(generator, latent_dim, num_images=5):\n",
    "    noise = np.random.normal(0, 1, (num_images, latent_dim))\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = (generated_images + 1) / 2.0  # Scale pixel values to [0, 1]\n",
    "    return generated_images\n",
    "\n",
    "# Generate and plot images\n",
    "num_images = 25\n",
    "generated_images = generate_images(generator, latent_dim=100, num_images=num_images)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(1, num_images, i + 1)\n",
    "    plt.imshow(generated_images[i])\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c02ec70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000265DE5FBB00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000265DE5FBB00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions for the generated images:\n",
      "Image 1: 0.00% Real, 100.00% Fake\n",
      "Image 2: 0.00% Real, 100.00% Fake\n",
      "Image 3: 0.00% Real, 100.00% Fake\n",
      "Image 4: 0.00% Real, 100.00% Fake\n",
      "Image 5: 0.00% Real, 100.00% Fake\n",
      "Image 6: 0.00% Real, 100.00% Fake\n",
      "Image 7: 0.00% Real, 100.00% Fake\n",
      "Image 8: 0.00% Real, 100.00% Fake\n",
      "Image 9: 0.00% Real, 100.00% Fake\n",
      "Image 10: 0.00% Real, 100.00% Fake\n",
      "Image 11: 0.00% Real, 100.00% Fake\n",
      "Image 12: 0.00% Real, 100.00% Fake\n",
      "Image 13: 0.00% Real, 100.00% Fake\n",
      "Image 14: 0.00% Real, 100.00% Fake\n",
      "Image 15: 0.00% Real, 100.00% Fake\n",
      "Image 16: 0.00% Real, 100.00% Fake\n",
      "Image 17: 0.00% Real, 100.00% Fake\n",
      "Image 18: 0.00% Real, 100.00% Fake\n",
      "Image 19: 0.00% Real, 100.00% Fake\n",
      "Image 20: 0.00% Real, 100.00% Fake\n",
      "Image 21: 0.00% Real, 100.00% Fake\n",
      "Image 22: 0.00% Real, 100.00% Fake\n",
      "Image 23: 0.00% Real, 100.00% Fake\n",
      "Image 24: 0.00% Real, 100.00% Fake\n",
      "Image 25: 0.00% Real, 100.00% Fake\n"
     ]
    }
   ],
   "source": [
    "# Load the discriminator model\n",
    "discriminator = load_model(r'C:\\Users\\akagg\\Downloads\\archive\\Dataset\\Deepfake\\discriminator.h5')\n",
    "\n",
    "# Function to test generated images using the discriminator\n",
    "def test_discriminator(discriminator, images):\n",
    "    # Normalize the pixel values to [-1, 1]\n",
    "    images = (images - 0.5) * 2\n",
    "    # Predict the authenticity of the images\n",
    "    predictions = discriminator.predict(images)\n",
    "    return predictions\n",
    "\n",
    "# Test the generated images using the discriminator\n",
    "predictions = test_discriminator(discriminator, generated_images)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Predictions for the generated images:\")\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(\"Image {}: {:.2f}% Real, {:.2f}% Fake\".format(i+1, pred[0]*100, (1-pred[0])*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "941b04cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predictions for the sample images:\n",
      "Image 1: 99.97% Real, 0.03% Fake\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "SIZE = 128\n",
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_images(image_paths, size=(SIZE, SIZE)):\n",
    "    loaded_images = []\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        img = cv2.resize(img, size)\n",
    "        img = (img - 127.5) / 127.5  # Normalize pixel values to [-1, 1]\n",
    "        loaded_images.append(img)\n",
    "    return np.array(loaded_images)\n",
    "\n",
    "# Example usage:\n",
    "image_paths = [r\"C:\\Users\\akagg\\Downloads\\archive\\Dataset\\Test\\Real\\real_94.jpg\"]  # List of paths to your sample images\n",
    "sample_images = load_and_preprocess_images(image_paths)\n",
    "\n",
    "# Test the sample images using the discriminator\n",
    "predictions = test_discriminator(discriminator, sample_images)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Predictions for the sample images:\")\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(\"Image {}: {:.2f}% Real, {:.2f}% Fake\".format(i+1, pred[0]*100, (1-pred[0])*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "628a65cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "Predictions for the sample images:\n",
      "Image 1: 100.00% Real, 0.00% Fake\n",
      "Image 2: 8.12% Real, 91.88% Fake\n",
      "Image 3: 99.96% Real, 0.04% Fake\n",
      "Image 4: 99.10% Real, 0.90% Fake\n",
      "Image 5: 99.07% Real, 0.93% Fake\n",
      "Image 6: 99.99% Real, 0.01% Fake\n",
      "Image 7: 0.00% Real, 100.00% Fake\n",
      "Image 8: 79.87% Real, 20.13% Fake\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "SIZE = 128\n",
    "def load_and_preprocess_images_from_folder(folder_path, size=(SIZE, SIZE)):\n",
    "    loaded_images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "            img = cv2.resize(img, size)\n",
    "            img = (img - 127.5) / 127.5  # Normalize pixel values to [-1, 1]\n",
    "            loaded_images.append(img)\n",
    "        else:\n",
    "            print(f\"Warning: Unable to read image '{img_path}'. Skipping...\")\n",
    "    return np.array(loaded_images)\n",
    "\n",
    "# Example usage:\n",
    "folder_path = r'C:\\Users\\akagg\\Downloads\\archive\\Dataset\\Test\\test1'  # Folder containing sample images\n",
    "sample_images = load_and_preprocess_images_from_folder(folder_path)\n",
    "\n",
    "# Test the sample images using the discriminator\n",
    "predictions = test_discriminator(discriminator, sample_images)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Predictions for the sample images:\")\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(\"Image {}: {:.2f}% Real, {:.2f}% Fake\".format(i+1, pred[0]*100, (1-pred[0])*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fe227f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
